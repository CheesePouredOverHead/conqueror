[2024-05-27 23:24:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 653
envstep_count: 6405
train_sample_count: 6405
avg_envstep_per_episode: 9.808575803981624
avg_sample_per_episode: 9.808575803981624
avg_envstep_per_sec: 180.12658577008742
avg_train_sample_per_sec: 180.12658577008742
avg_episode_per_sec: 18.36419367804326
reward_mean: 43.9326171875
reward_std: 64.13878631591797
reward_max: 328.0
reward_min: -50.0
total_envstep_count: 6464
total_train_sample_count: 6405
total_episode_count: 653
[2024-05-27 23:31:29][sample_serial_collector.py:406][INFO] collect end:
episode_count: 274
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 11.697080291970803
avg_sample_per_episode: 11.697080291970803
avg_envstep_per_sec: 173.67458881991607
avg_train_sample_per_sec: 173.67458881991607
avg_episode_per_sec: 14.847687156523246
reward_mean: 74.92700958251953
reward_std: 83.0896224975586
reward_max: 436.0
reward_min: -38.0
total_envstep_count: 9708
total_train_sample_count: 9610
total_episode_count: 927
[2024-05-27 23:38:46][sample_serial_collector.py:406][INFO] collect end:
episode_count: 241
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 13.28630705394191
avg_sample_per_episode: 13.28630705394191
avg_envstep_per_sec: 180.4886603227966
avg_train_sample_per_sec: 180.4886603227966
avg_episode_per_sec: 13.584561879386001
reward_mean: 101.24481201171875
reward_std: 101.02188110351562
reward_max: 472.0
reward_min: -50.0
total_envstep_count: 12942
total_train_sample_count: 12812
total_episode_count: 1168
[2024-05-27 23:46:07][sample_serial_collector.py:406][INFO] collect end:
episode_count: 235
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 13.629787234042553
avg_sample_per_episode: 13.629787234042553
avg_envstep_per_sec: 182.0966706603291
avg_train_sample_per_sec: 182.0966706603291
avg_episode_per_sec: 13.360199064994486
reward_mean: 103.16595458984375
reward_std: 106.67166900634766
reward_max: 556.0
reward_min: -38.0
total_envstep_count: 16204
total_train_sample_count: 16015
total_episode_count: 1403
[2024-05-27 23:53:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 207
envstep_count: 3229
train_sample_count: 3229
avg_envstep_per_episode: 15.599033816425122
avg_sample_per_episode: 15.599033816425122
avg_envstep_per_sec: 184.6658099459577
avg_train_sample_per_sec: 184.6658099459577
avg_episode_per_sec: 11.838285121961365
reward_mean: 135.85507202148438
reward_std: 130.6977081298828
reward_max: 610.0
reward_min: -50.0
total_envstep_count: 19508
total_train_sample_count: 19244
total_episode_count: 1610
[2024-05-28 00:00:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 17.06382978723404
avg_sample_per_episode: 17.06382978723404
avg_envstep_per_sec: 183.67196327385048
avg_train_sample_per_sec: 183.67196327385048
avg_episode_per_sec: 10.763818296597224
reward_mean: 162.2872314453125
reward_std: 153.5778350830078
reward_max: 1226.0
reward_min: -50.0
total_envstep_count: 22760
total_train_sample_count: 22452
total_episode_count: 1798
[2024-05-28 00:07:58][sample_serial_collector.py:406][INFO] collect end:
episode_count: 177
envstep_count: 3262
train_sample_count: 3262
avg_envstep_per_episode: 18.429378531073446
avg_sample_per_episode: 18.429378531073446
avg_envstep_per_sec: 183.88635658002005
avg_train_sample_per_sec: 183.88635658002005
avg_episode_per_sec: 9.97789243245357
reward_mean: 182.8135528564453
reward_std: 155.03750610351562
reward_max: 766.0
reward_min: -50.0
total_envstep_count: 26054
total_train_sample_count: 25714
total_episode_count: 1975
[2024-05-28 00:15:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 165
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 19.44242424242424
avg_sample_per_episode: 19.44242424242424
avg_envstep_per_sec: 188.25605250762825
avg_train_sample_per_sec: 188.25605250762825
avg_episode_per_sec: 9.682745842817539
reward_mean: 195.41818237304688
reward_std: 162.05886840820312
reward_max: 892.0
reward_min: -50.0
total_envstep_count: 29342
total_train_sample_count: 28922
total_episode_count: 2140
[2024-05-28 00:22:49][sample_serial_collector.py:406][INFO] collect end:
episode_count: 156
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 20.583333333333332
avg_sample_per_episode: 20.583333333333332
avg_envstep_per_sec: 186.33821161071418
avg_train_sample_per_sec: 186.33821161071418
avg_episode_per_sec: 9.052868580277613
reward_mean: 218.42308044433594
reward_std: 161.70645141601562
reward_max: 712.0
reward_min: -50.0
total_envstep_count: 32622
total_train_sample_count: 32133
total_episode_count: 2296
[2024-05-28 00:30:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 21.516778523489933
avg_sample_per_episode: 21.516778523489933
avg_envstep_per_sec: 188.55518668272538
avg_train_sample_per_sec: 188.55518668272538
avg_episode_per_sec: 8.763169936283868
reward_mean: 232.24160766601562
reward_std: 178.19752502441406
reward_max: 730.0
reward_min: -38.0
total_envstep_count: 35890
total_train_sample_count: 35339
total_episode_count: 2445
[2024-05-28 00:37:35][sample_serial_collector.py:406][INFO] collect end:
episode_count: 155
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 20.729032258064517
avg_sample_per_episode: 20.729032258064517
avg_envstep_per_sec: 186.2448274579404
avg_train_sample_per_sec: 186.2448274579404
avg_episode_per_sec: 8.98473335075654
reward_mean: 219.03225708007812
reward_std: 154.1299591064453
reward_max: 646.0
reward_min: -38.0
total_envstep_count: 39200
total_train_sample_count: 38552
total_episode_count: 2600
[2024-05-28 00:44:51][sample_serial_collector.py:406][INFO] collect end:
episode_count: 148
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 21.64864864864865
avg_sample_per_episode: 21.64864864864865
avg_envstep_per_sec: 189.01065190469689
avg_train_sample_per_sec: 189.01065190469689
avg_episode_per_sec: 8.730829114199482
reward_mean: 237.35134887695312
reward_std: 152.9246826171875
reward_max: 652.0
reward_min: -38.0
total_envstep_count: 42485
total_train_sample_count: 41756
total_episode_count: 2748
[2024-05-28 00:52:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 154
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 20.792207792207794
avg_sample_per_episode: 20.792207792207794
avg_envstep_per_sec: 186.78102801026193
avg_train_sample_per_sec: 186.78102801026193
avg_episode_per_sec: 8.983222458957007
reward_mean: 217.1558380126953
reward_std: 159.68211364746094
reward_max: 868.0
reward_min: -38.0
total_envstep_count: 45780
total_train_sample_count: 44958
total_episode_count: 2902
[2024-05-28 00:59:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 22.333333333333332
avg_sample_per_episode: 22.333333333333332
avg_envstep_per_sec: 188.187783922639
avg_train_sample_per_sec: 188.187783922639
avg_episode_per_sec: 8.426318683103238
reward_mean: 245.4166717529297
reward_std: 171.28919982910156
reward_max: 904.0
reward_min: -38.0
total_envstep_count: 49080
total_train_sample_count: 48174
total_episode_count: 3046
[2024-05-28 01:06:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 134
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 23.925373134328357
avg_sample_per_episode: 23.925373134328357
avg_envstep_per_sec: 186.8529926283827
avg_train_sample_per_sec: 186.8529926283827
avg_episode_per_sec: 7.8098256432324655
reward_mean: 271.0
reward_std: 187.4413299560547
reward_max: 1006.0
reward_min: -38.0
total_envstep_count: 52380
total_train_sample_count: 51380
total_episode_count: 3180
[2024-05-28 01:13:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 142
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 22.732394366197184
avg_sample_per_episode: 22.732394366197184
avg_envstep_per_sec: 189.63948062139715
avg_train_sample_per_sec: 189.63948062139715
avg_episode_per_sec: 8.342257202056503
reward_mean: 251.6056365966797
reward_std: 184.3900146484375
reward_max: 880.0
reward_min: -50.0
total_envstep_count: 55697
total_train_sample_count: 54608
total_episode_count: 3322
[2024-05-28 01:21:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 136
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 23.75
avg_sample_per_episode: 23.75
avg_envstep_per_sec: 187.26538588227692
avg_train_sample_per_sec: 187.26538588227692
avg_episode_per_sec: 7.884858352937975
reward_mean: 267.73529052734375
reward_std: 181.37252807617188
reward_max: 736.0
reward_min: -50.0
total_envstep_count: 59027
total_train_sample_count: 57838
total_episode_count: 3458
[2024-05-28 01:28:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 21.35333333333333
avg_sample_per_episode: 21.35333333333333
avg_envstep_per_sec: 187.50130308003762
avg_train_sample_per_sec: 187.50130308003762
avg_episode_per_sec: 8.78089149609917
reward_mean: 227.55999755859375
reward_std: 178.01495361328125
reward_max: 868.0
reward_min: -26.0
total_envstep_count: 62330
total_train_sample_count: 61041
total_episode_count: 3608
[2024-05-28 01:35:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 136
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 23.639705882352942
avg_sample_per_episode: 23.639705882352942
avg_envstep_per_sec: 188.1845709765756
avg_train_sample_per_sec: 188.1845709765756
avg_episode_per_sec: 7.960529285478781
reward_mean: 269.6176452636719
reward_std: 203.5045166015625
reward_max: 1256.0
reward_min: -26.0
total_envstep_count: 65653
total_train_sample_count: 64256
total_episode_count: 3744
[2024-05-28 01:42:37][sample_serial_collector.py:406][INFO] collect end:
episode_count: 139
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 23.071942446043167
avg_sample_per_episode: 23.071942446043167
avg_envstep_per_sec: 193.93966319161143
avg_train_sample_per_sec: 193.93966319161143
avg_episode_per_sec: 8.405866287381974
reward_mean: 258.1438903808594
reward_std: 214.16790771484375
reward_max: 1328.0
reward_min: -50.0
total_envstep_count: 68965
total_train_sample_count: 67463
total_episode_count: 3883
[2024-05-28 01:49:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 132
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 24.310606060606062
avg_sample_per_episode: 24.310606060606062
avg_envstep_per_sec: 191.71872421851907
avg_train_sample_per_sec: 191.71872421851907
avg_episode_per_sec: 7.8862173876112545
reward_mean: 280.257568359375
reward_std: 207.73707580566406
reward_max: 1196.0
reward_min: -38.0
total_envstep_count: 72279
total_train_sample_count: 70672
total_episode_count: 4015
[2024-05-28 01:56:55][sample_serial_collector.py:406][INFO] collect end:
episode_count: 142
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 22.54225352112676
avg_sample_per_episode: 22.54225352112676
avg_envstep_per_sec: 189.537249612569
avg_train_sample_per_sec: 189.537249612569
avg_episode_per_sec: 8.408087924081475
reward_mean: 246.85916137695312
reward_std: 208.22218322753906
reward_max: 1238.0
reward_min: -50.0
total_envstep_count: 75603
total_train_sample_count: 73873
total_episode_count: 4157
[2024-05-28 02:04:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 139
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 23.20863309352518
avg_sample_per_episode: 23.20863309352518
avg_envstep_per_sec: 190.96596125356078
avg_train_sample_per_sec: 190.96596125356078
avg_episode_per_sec: 8.228229576641336
reward_mean: 261.8705139160156
reward_std: 181.7946014404297
reward_max: 856.0
reward_min: -38.0
total_envstep_count: 78892
total_train_sample_count: 77099
total_episode_count: 4296
[2024-05-28 02:11:14][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 25.2578125
avg_sample_per_episode: 25.2578125
avg_envstep_per_sec: 187.3459812854406
avg_train_sample_per_sec: 187.3459812854406
avg_episode_per_sec: 7.417347851696999
reward_mean: 288.859375
reward_std: 177.5393829345703
reward_max: 820.0
reward_min: -38.0
total_envstep_count: 82215
total_train_sample_count: 80332
total_episode_count: 4424
[2024-05-28 02:18:26][sample_serial_collector.py:406][INFO] collect end:
episode_count: 135
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 23.77777777777778
avg_sample_per_episode: 23.77777777777778
avg_envstep_per_sec: 193.988882423152
avg_train_sample_per_sec: 193.988882423152
avg_episode_per_sec: 8.158410943029757
reward_mean: 270.6666564941406
reward_std: 169.69879150390625
reward_max: 898.0
reward_min: -26.0
total_envstep_count: 85531
total_train_sample_count: 83542
total_episode_count: 4559
[2024-05-28 02:25:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 130
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 24.746153846153845
avg_sample_per_episode: 24.746153846153845
avg_envstep_per_sec: 191.41738211812566
avg_train_sample_per_sec: 191.41738211812566
avg_episode_per_sec: 7.73523769827676
reward_mean: 288.23077392578125
reward_std: 210.77259826660156
reward_max: 1262.0
reward_min: -50.0
total_envstep_count: 88826
total_train_sample_count: 86759
total_episode_count: 4689
[2024-05-28 02:33:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 123
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 26.024390243902438
avg_sample_per_episode: 26.024390243902438
avg_envstep_per_sec: 190.2195116202615
avg_train_sample_per_sec: 190.2195116202615
avg_episode_per_sec: 7.309278328426169
reward_mean: 304.7804870605469
reward_std: 201.15660095214844
reward_max: 820.0
reward_min: -26.0
total_envstep_count: 92141
total_train_sample_count: 89960
total_episode_count: 4812
[2024-05-28 02:40:19][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3302
train_sample_count: 3302
avg_envstep_per_episode: 25.796875
avg_sample_per_episode: 25.796875
avg_envstep_per_sec: 189.94786055967808
avg_train_sample_per_sec: 189.94786055967808
avg_episode_per_sec: 7.3632120386549955
reward_mean: 306.015625
reward_std: 184.03184509277344
reward_max: 760.0
reward_min: -38.0
total_envstep_count: 95512
total_train_sample_count: 93262
total_episode_count: 4940
[2024-05-28 02:47:29][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 25.1640625
avg_sample_per_episode: 25.1640625
avg_envstep_per_sec: 192.4213935546161
avg_train_sample_per_sec: 192.4213935546161
avg_episode_per_sec: 7.646674441164501
reward_mean: 289.65625
reward_std: 184.5110321044922
reward_max: 820.0
reward_min: -50.0
total_envstep_count: 98846
total_train_sample_count: 96483
total_episode_count: 5068
[2024-05-28 02:54:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 25.140625
avg_sample_per_episode: 25.140625
avg_envstep_per_sec: 194.65609224734342
avg_train_sample_per_sec: 194.65609224734342
avg_episode_per_sec: 7.742691052722175
reward_mean: 293.15625
reward_std: 202.22181701660156
reward_max: 1214.0
reward_min: -38.0
total_envstep_count: 102204
total_train_sample_count: 99701
total_episode_count: 5196
[2024-05-28 03:01:48][sample_serial_collector.py:406][INFO] collect end:
episode_count: 138
envstep_count: 3244
train_sample_count: 3244
avg_envstep_per_episode: 23.507246376811594
avg_sample_per_episode: 23.507246376811594
avg_envstep_per_sec: 192.00262569801563
avg_train_sample_per_sec: 192.00262569801563
avg_episode_per_sec: 8.167805902073415
reward_mean: 269.521728515625
reward_std: 160.18966674804688
reward_max: 646.0
reward_min: -38.0
total_envstep_count: 105517
total_train_sample_count: 102945
total_episode_count: 5334
[2024-05-28 03:09:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 131
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 24.480916030534353
avg_sample_per_episode: 24.480916030534353
avg_envstep_per_sec: 191.9673826058507
avg_train_sample_per_sec: 191.9673826058507
avg_episode_per_sec: 7.841511419197519
reward_mean: 278.68701171875
reward_std: 235.01499938964844
reward_max: 1244.0
reward_min: -50.0
total_envstep_count: 108822
total_train_sample_count: 106152
total_episode_count: 5465
[2024-05-28 03:16:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 137
envstep_count: 3276
train_sample_count: 3276
avg_envstep_per_episode: 23.912408759124087
avg_sample_per_episode: 23.912408759124087
avg_envstep_per_sec: 187.52927613984693
avg_train_sample_per_sec: 187.52927613984693
avg_episode_per_sec: 7.842341523552817
reward_mean: 267.0802917480469
reward_std: 176.01409912109375
reward_max: 772.0
reward_min: -26.0
total_envstep_count: 112200
total_train_sample_count: 109428
total_episode_count: 5602
[2024-05-28 03:23:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 126
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 25.53968253968254
avg_sample_per_episode: 25.53968253968254
avg_envstep_per_sec: 190.59773356767374
avg_train_sample_per_sec: 190.59773356767374
avg_episode_per_sec: 7.462807467224018
reward_mean: 300.1269836425781
reward_std: 211.78152465820312
reward_max: 1262.0
reward_min: -38.0
total_envstep_count: 115482
total_train_sample_count: 112646
total_episode_count: 5728
[2024-05-28 03:30:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 135
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 23.725925925925925
avg_sample_per_episode: 23.725925925925925
avg_envstep_per_sec: 193.31651202097953
avg_train_sample_per_sec: 193.31651202097953
avg_episode_per_sec: 8.147901693047842
reward_mean: 263.0666809082031
reward_std: 176.08462524414062
reward_max: 736.0
reward_min: -50.0
total_envstep_count: 118804
total_train_sample_count: 115849
total_episode_count: 5863
[2024-05-28 03:37:47][sample_serial_collector.py:406][INFO] collect end:
episode_count: 123
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 26.048780487804876
avg_sample_per_episode: 26.048780487804876
avg_envstep_per_sec: 193.50826439292806
avg_train_sample_per_sec: 193.50826439292806
avg_episode_per_sec: 7.4286880525375
reward_mean: 310.6178894042969
reward_std: 187.4390869140625
reward_max: 1304.0
reward_min: -14.0
total_envstep_count: 122207
total_train_sample_count: 119053
total_episode_count: 5986
[2024-05-28 03:45:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 125
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 25.6
avg_sample_per_episode: 25.6
avg_envstep_per_sec: 188.23215025054006
avg_train_sample_per_sec: 188.23215025054006
avg_episode_per_sec: 7.352818369161721
reward_mean: 314.239990234375
reward_std: 201.0483856201172
reward_max: 1190.0
reward_min: -38.0
total_envstep_count: 125510
total_train_sample_count: 122253
total_episode_count: 6111
[2024-05-28 03:52:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 124
envstep_count: 3236
train_sample_count: 3236
avg_envstep_per_episode: 26.096774193548388
avg_sample_per_episode: 26.096774193548388
avg_envstep_per_sec: 192.94135596790304
avg_train_sample_per_sec: 192.94135596790304
avg_episode_per_sec: 7.393302886285531
reward_mean: 312.9838562011719
reward_std: 246.66673278808594
reward_max: 1274.0
reward_min: -50.0
total_envstep_count: 128880
total_train_sample_count: 125489
total_episode_count: 6235
[2024-05-28 03:59:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 123
envstep_count: 3251
train_sample_count: 3251
avg_envstep_per_episode: 26.43089430894309
avg_sample_per_episode: 26.43089430894309
avg_envstep_per_sec: 191.38841477476416
avg_train_sample_per_sec: 191.38841477476416
avg_episode_per_sec: 7.2410873630562875
reward_mean: 321.7723693847656
reward_std: 221.07632446289062
reward_max: 1262.0
reward_min: -38.0
total_envstep_count: 132225
total_train_sample_count: 128740
total_episode_count: 6358
[2024-05-28 04:06:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 125
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 25.736
avg_sample_per_episode: 25.736
avg_envstep_per_sec: 194.35338955825858
avg_train_sample_per_sec: 194.35338955825858
avg_episode_per_sec: 7.551810287467306
reward_mean: 306.8800048828125
reward_std: 237.89024353027344
reward_max: 1274.0
reward_min: -50.0
total_envstep_count: 135529
total_train_sample_count: 131957
total_episode_count: 6483
[2024-05-28 04:14:02][sample_serial_collector.py:406][INFO] collect end:
episode_count: 133
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 24.165413533834588
avg_sample_per_episode: 24.165413533834588
avg_envstep_per_sec: 190.55773563116952
avg_train_sample_per_sec: 190.55773563116952
avg_episode_per_sec: 7.885556577145471
reward_mean: 274.27069091796875
reward_std: 190.40721130371094
reward_max: 910.0
reward_min: 4.0
total_envstep_count: 138864
total_train_sample_count: 135171
total_episode_count: 6616
[2024-05-28 04:21:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 127
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 25.19685039370079
avg_sample_per_episode: 25.19685039370079
avg_envstep_per_sec: 188.06076666313248
avg_train_sample_per_sec: 188.06076666313248
avg_episode_per_sec: 7.463661676943071
reward_mean: 298.83465576171875
reward_std: 212.35350036621094
reward_max: 1232.0
reward_min: -50.0
total_envstep_count: 142182
total_train_sample_count: 138371
total_episode_count: 6743
[2024-05-28 04:28:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 123
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 26.056910569105693
avg_sample_per_episode: 26.056910569105693
avg_envstep_per_sec: 191.768799296373
avg_train_sample_per_sec: 191.768799296373
avg_episode_per_sec: 7.359613826350664
reward_mean: 306.9593505859375
reward_std: 198.23159790039062
reward_max: 1172.0
reward_min: -38.0
total_envstep_count: 145461
total_train_sample_count: 141576
total_episode_count: 6866
[2024-05-28 04:35:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 125
envstep_count: 3240
train_sample_count: 3240
avg_envstep_per_episode: 25.92
avg_sample_per_episode: 25.92
avg_envstep_per_sec: 189.3726183093127
avg_train_sample_per_sec: 189.3726183093127
avg_episode_per_sec: 7.306042373044472
reward_mean: 298.0
reward_std: 188.15756225585938
reward_max: 880.0
reward_min: -38.0
total_envstep_count: 148798
total_train_sample_count: 144816
total_episode_count: 6991
[2024-05-28 04:42:59][sample_serial_collector.py:406][INFO] collect end:
episode_count: 126
envstep_count: 3241
train_sample_count: 3241
avg_envstep_per_episode: 25.72222222222222
avg_sample_per_episode: 25.72222222222222
avg_envstep_per_sec: 189.59332327406278
avg_train_sample_per_sec: 189.59332327406278
avg_episode_per_sec: 7.370798744995961
reward_mean: 303.4603271484375
reward_std: 196.07196044921875
reward_max: 1268.0
reward_min: -14.0
total_envstep_count: 152131
total_train_sample_count: 148057
total_episode_count: 7117
[2024-05-28 04:50:22][sample_serial_collector.py:406][INFO] collect end:
episode_count: 130
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 24.615384615384617
avg_sample_per_episode: 24.615384615384617
avg_envstep_per_sec: 192.71989347392372
avg_train_sample_per_sec: 192.71989347392372
avg_episode_per_sec: 7.829245672378152
reward_mean: 281.3846130371094
reward_std: 197.2889862060547
reward_max: 790.0
reward_min: -50.0
total_envstep_count: 155514
total_train_sample_count: 151257
total_episode_count: 7247
[2024-05-28 04:57:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 131
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 24.580152671755727
avg_sample_per_episode: 24.580152671755727
avg_envstep_per_sec: 192.31187330196695
avg_train_sample_per_sec: 192.31187330196695
avg_episode_per_sec: 7.82386813744027
reward_mean: 294.9618225097656
reward_std: 215.4287567138672
reward_max: 1280.0
reward_min: -50.0
total_envstep_count: 158846
total_train_sample_count: 154477
total_episode_count: 7378
[2024-05-28 05:04:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 25.0078125
avg_sample_per_episode: 25.0078125
avg_envstep_per_sec: 192.89387764883486
avg_train_sample_per_sec: 192.89387764883486
avg_episode_per_sec: 7.7133446857391
reward_mean: 289.03125
reward_std: 189.0186767578125
reward_max: 1196.0
reward_min: -50.0
total_envstep_count: 162208
total_train_sample_count: 157678
total_episode_count: 7506
[2024-05-28 05:12:07][sample_serial_collector.py:406][INFO] collect end:
episode_count: 140
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 23.09285714285714
avg_sample_per_episode: 23.09285714285714
avg_envstep_per_sec: 189.12398181216835
avg_train_sample_per_sec: 189.12398181216835
avg_episode_per_sec: 8.189717740087712
reward_mean: 265.71429443359375
reward_std: 193.22828674316406
reward_max: 1244.0
reward_min: -38.0
total_envstep_count: 165504
total_train_sample_count: 160911
total_episode_count: 7646
[2024-05-28 05:19:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 126
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 25.515873015873016
avg_sample_per_episode: 25.515873015873016
avg_envstep_per_sec: 191.04205190263696
avg_train_sample_per_sec: 191.04205190263696
avg_episode_per_sec: 7.487184615779862
reward_mean: 291.79364013671875
reward_std: 219.95062255859375
reward_max: 1226.0
reward_min: -38.0
total_envstep_count: 168780
total_train_sample_count: 164126
total_episode_count: 7772
[2024-05-28 05:26:42][sample_serial_collector.py:406][INFO] collect end:
episode_count: 130
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 24.753846153846155
avg_sample_per_episode: 24.753846153846155
avg_envstep_per_sec: 190.03551960281808
avg_train_sample_per_sec: 190.03551960281808
avg_episode_per_sec: 7.677009803718567
reward_mean: 280.1230773925781
reward_std: 189.0414276123047
reward_max: 1214.0
reward_min: -38.0
total_envstep_count: 172137
total_train_sample_count: 167344
total_episode_count: 7902
[2024-05-28 05:33:57][sample_serial_collector.py:406][INFO] collect end:
episode_count: 131
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 24.46564885496183
avg_sample_per_episode: 24.46564885496183
avg_envstep_per_sec: 189.70712220647667
avg_train_sample_per_sec: 189.70712220647667
avg_episode_per_sec: 7.754019659609499
reward_mean: 281.0534362792969
reward_std: 202.57447814941406
reward_max: 832.0
reward_min: -50.0
total_envstep_count: 175532
total_train_sample_count: 170549
total_episode_count: 8033
[2024-05-28 05:41:11][sample_serial_collector.py:406][INFO] collect end:
episode_count: 129
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 24.837209302325583
avg_sample_per_episode: 24.837209302325583
avg_envstep_per_sec: 190.48890832103237
avg_train_sample_per_sec: 190.48890832103237
avg_episode_per_sec: 7.669497245135198
reward_mean: 299.9224853515625
reward_std: 221.15782165527344
reward_max: 1346.0
reward_min: -38.0
total_envstep_count: 178850
total_train_sample_count: 173753
total_episode_count: 8162
[2024-05-28 05:48:26][sample_serial_collector.py:406][INFO] collect end:
episode_count: 136
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 23.63235294117647
avg_sample_per_episode: 23.63235294117647
avg_envstep_per_sec: 190.15072344902998
avg_train_sample_per_sec: 190.15072344902998
avg_episode_per_sec: 8.046203605808364
reward_mean: 263.7205810546875
reward_std: 175.75872802734375
reward_max: 820.0
reward_min: -50.0
total_envstep_count: 182205
total_train_sample_count: 176967
total_episode_count: 8298
[2024-05-28 05:55:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 129
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 24.92248062015504
avg_sample_per_episode: 24.92248062015504
avg_envstep_per_sec: 190.08588208834044
avg_train_sample_per_sec: 190.08588208834044
avg_episode_per_sec: 7.62708515999873
reward_mean: 287.19378662109375
reward_std: 205.15655517578125
reward_max: 1178.0
reward_min: -38.0
total_envstep_count: 185585
total_train_sample_count: 180182
total_episode_count: 8427
[2024-05-28 06:02:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 25.09375
avg_sample_per_episode: 25.09375
avg_envstep_per_sec: 192.3984087723854
avg_train_sample_per_sec: 192.3984087723854
avg_episode_per_sec: 7.667184409360316
reward_mean: 296.6875
reward_std: 197.0045166015625
reward_max: 796.0
reward_min: -50.0
total_envstep_count: 188863
total_train_sample_count: 183394
total_episode_count: 8555
[2024-05-28 06:10:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 25.046875
avg_sample_per_episode: 25.046875
avg_envstep_per_sec: 187.43339116217066
avg_train_sample_per_sec: 187.43339116217066
avg_episode_per_sec: 7.4833044506418736
reward_mean: 284.453125
reward_std: 211.69174194335938
reward_max: 862.0
reward_min: -50.0
total_envstep_count: 192148
total_train_sample_count: 186600
total_episode_count: 8683
[2024-05-28 06:17:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 135
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 23.925925925925927
avg_sample_per_episode: 23.925925925925927
avg_envstep_per_sec: 186.6126492942326
avg_train_sample_per_sec: 186.6126492942326
avg_episode_per_sec: 7.7995998931026005
reward_mean: 268.3555603027344
reward_std: 166.16900634765625
reward_max: 772.0
reward_min: -38.0
total_envstep_count: 195502
total_train_sample_count: 189830
total_episode_count: 8818
[2024-05-28 06:24:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 121
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 26.454545454545453
avg_sample_per_episode: 26.454545454545453
avg_envstep_per_sec: 188.7133930195518
avg_train_sample_per_sec: 188.7133930195518
avg_episode_per_sec: 7.133495956065532
reward_mean: 314.9090881347656
reward_std: 198.49000549316406
reward_max: 916.0
reward_min: -50.0
total_envstep_count: 198837
total_train_sample_count: 193031
total_episode_count: 8939
[2024-05-28 06:32:01][sample_serial_collector.py:406][INFO] collect end:
episode_count: 125
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 25.608
avg_sample_per_episode: 25.608
avg_envstep_per_sec: 191.60757280052198
avg_train_sample_per_sec: 191.60757280052198
avg_episode_per_sec: 7.482332583588018
reward_mean: 303.23199462890625
reward_std: 194.4666290283203
reward_max: 850.0
reward_min: -50.0
total_envstep_count: 202175
total_train_sample_count: 196232
total_episode_count: 9064
[2024-05-28 06:39:18][sample_serial_collector.py:406][INFO] collect end:
episode_count: 133
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 24.32330827067669
avg_sample_per_episode: 24.32330827067669
avg_envstep_per_sec: 189.88430519482398
avg_train_sample_per_sec: 189.88430519482398
avg_episode_per_sec: 7.80668086272383
reward_mean: 284.631591796875
reward_std: 190.1075897216797
reward_max: 1226.0
reward_min: -50.0
total_envstep_count: 205573
total_train_sample_count: 199467
total_episode_count: 9197
[2024-05-28 06:46:41][sample_serial_collector.py:406][INFO] collect end:
episode_count: 133
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 24.218045112781954
avg_sample_per_episode: 24.218045112781954
avg_envstep_per_sec: 187.2886464145382
avg_train_sample_per_sec: 187.2886464145382
avg_episode_per_sec: 7.733433707896175
reward_mean: 285.6691589355469
reward_std: 200.11337280273438
reward_max: 1160.0
reward_min: -38.0
total_envstep_count: 208876
total_train_sample_count: 202688
total_episode_count: 9330
[2024-05-28 06:53:56][sample_serial_collector.py:406][INFO] collect end:
episode_count: 131
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 24.625954198473284
avg_sample_per_episode: 24.625954198473284
avg_envstep_per_sec: 187.2008744631634
avg_train_sample_per_sec: 187.2008744631634
avg_episode_per_sec: 7.601771405664725
reward_mean: 284.7175598144531
reward_std: 183.8070831298828
reward_max: 1036.0
reward_min: -38.0
total_envstep_count: 212227
total_train_sample_count: 205914
total_episode_count: 9461
[2024-05-28 07:01:12][sample_serial_collector.py:406][INFO] collect end:
episode_count: 137
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 23.43065693430657
avg_sample_per_episode: 23.43065693430657
avg_envstep_per_sec: 188.2141598782725
avg_train_sample_per_sec: 188.2141598782725
avg_episode_per_sec: 8.032816169259606
reward_mean: 261.6496276855469
reward_std: 188.2095184326172
reward_max: 790.0
reward_min: -50.0
total_envstep_count: 215522
total_train_sample_count: 209124
total_episode_count: 9598
[2024-05-28 07:08:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 135
envstep_count: 3245
train_sample_count: 3245
avg_envstep_per_episode: 24.037037037037038
avg_sample_per_episode: 24.037037037037038
avg_envstep_per_sec: 184.76049130040275
avg_train_sample_per_sec: 184.76049130040275
avg_episode_per_sec: 7.68649193391506
reward_mean: 266.9333190917969
reward_std: 173.5985565185547
reward_max: 730.0
reward_min: -26.0
total_envstep_count: 218812
total_train_sample_count: 212369
total_episode_count: 9733
[2024-05-28 07:15:56][sample_serial_collector.py:406][INFO] collect end:
episode_count: 122
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 26.229508196721312
avg_sample_per_episode: 26.229508196721312
avg_envstep_per_sec: 188.9583939977778
avg_train_sample_per_sec: 188.9583939977778
avg_episode_per_sec: 7.204038771165278
reward_mean: 301.3934326171875
reward_std: 192.1228790283203
reward_max: 748.0
reward_min: -38.0
total_envstep_count: 222141
total_train_sample_count: 215569
total_episode_count: 9855
[2024-05-28 07:23:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 130
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 24.623076923076923
avg_sample_per_episode: 24.623076923076923
avg_envstep_per_sec: 184.88879547701697
avg_train_sample_per_sec: 184.88879547701697
avg_episode_per_sec: 7.50876082849491
reward_mean: 287.8769226074219
reward_std: 188.72622680664062
reward_max: 1196.0
reward_min: -50.0
total_envstep_count: 225453
total_train_sample_count: 218770
total_episode_count: 9985
[2024-05-28 07:30:34][sample_serial_collector.py:406][INFO] collect end:
episode_count: 124
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 25.806451612903224
avg_sample_per_episode: 25.806451612903224
avg_envstep_per_sec: 188.10720213987108
avg_train_sample_per_sec: 188.10720213987108
avg_episode_per_sec: 7.289154082920004
reward_mean: 295.6451721191406
reward_std: 203.3676300048828
reward_max: 772.0
reward_min: -270.0
total_envstep_count: 228750
total_train_sample_count: 221970
total_episode_count: 10109
[2024-05-28 07:37:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 134
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 23.895522388059703
avg_sample_per_episode: 23.895522388059703
avg_envstep_per_sec: 184.53025198826
avg_train_sample_per_sec: 184.53025198826
avg_episode_per_sec: 7.722377815873466
reward_mean: 269.47760009765625
reward_std: 187.66004943847656
reward_max: 718.0
reward_min: -38.0
total_envstep_count: 232041
total_train_sample_count: 225172
total_episode_count: 10243
[2024-05-28 07:45:14][sample_serial_collector.py:406][INFO] collect end:
episode_count: 131
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 24.65648854961832
avg_sample_per_episode: 24.65648854961832
avg_envstep_per_sec: 186.52233941198236
avg_train_sample_per_sec: 186.52233941198236
avg_episode_per_sec: 7.564837914232101
reward_mean: 284.198486328125
reward_std: 192.4850616455078
reward_max: 1244.0
reward_min: -50.0
total_envstep_count: 235391
total_train_sample_count: 228402
total_episode_count: 10374
[2024-05-28 07:52:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 126
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 25.428571428571427
avg_sample_per_episode: 25.428571428571427
avg_envstep_per_sec: 188.00216423272107
avg_train_sample_per_sec: 188.00216423272107
avg_episode_per_sec: 7.393343537241839
reward_mean: 300.0
reward_std: 191.77069091796875
reward_max: 826.0
reward_min: -50.0
total_envstep_count: 238736
total_train_sample_count: 231606
total_episode_count: 10500
[2024-05-28 07:59:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 130
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 24.66923076923077
avg_sample_per_episode: 24.66923076923077
avg_envstep_per_sec: 186.8677421313594
avg_train_sample_per_sec: 186.8677421313594
avg_episode_per_sec: 7.574931860641322
reward_mean: 289.30767822265625
reward_std: 192.93614196777344
reward_max: 1196.0
reward_min: -50.0
total_envstep_count: 242052
total_train_sample_count: 234813
total_episode_count: 10630
[2024-05-28 08:07:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 127
envstep_count: 3260
train_sample_count: 3260
avg_envstep_per_episode: 25.669291338582678
avg_sample_per_episode: 25.669291338582678
avg_envstep_per_sec: 187.62958616582458
avg_train_sample_per_sec: 187.62958616582458
avg_episode_per_sec: 7.3094961481778284
reward_mean: 299.2598571777344
reward_std: 184.4449920654297
reward_max: 1148.0
reward_min: -20.0
total_envstep_count: 245475
total_train_sample_count: 238073
total_episode_count: 10757
[2024-05-28 08:14:27][sample_serial_collector.py:406][INFO] collect end:
episode_count: 138
envstep_count: 3289
train_sample_count: 3289
avg_envstep_per_episode: 23.833333333333332
avg_sample_per_episode: 23.833333333333332
avg_envstep_per_sec: 189.81243190141117
avg_train_sample_per_sec: 189.81243190141117
avg_episode_per_sec: 7.964157981877391
reward_mean: 280.2463684082031
reward_std: 191.0915069580078
reward_max: 1178.0
reward_min: -38.0
total_envstep_count: 248873
total_train_sample_count: 241362
total_episode_count: 10895
[2024-05-28 08:22:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 134
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 24.067164179104477
avg_sample_per_episode: 24.067164179104477
avg_envstep_per_sec: 189.83936561773288
avg_train_sample_per_sec: 189.83936561773288
avg_episode_per_sec: 7.887899222566265
reward_mean: 277.47760009765625
reward_std: 191.83372497558594
reward_max: 1214.0
reward_min: -38.0
total_envstep_count: 252215
total_train_sample_count: 244587
total_episode_count: 11029
[2024-05-28 08:29:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 135
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 23.733333333333334
avg_sample_per_episode: 23.733333333333334
avg_envstep_per_sec: 187.1887255288844
avg_train_sample_per_sec: 187.1887255288844
avg_episode_per_sec: 7.887165401497938
reward_mean: 268.26666259765625
reward_std: 180.41265869140625
reward_max: 922.0
reward_min: -50.0
total_envstep_count: 255533
total_train_sample_count: 247791
total_episode_count: 11164
[2024-05-28 08:36:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 133
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 24.225563909774436
avg_sample_per_episode: 24.225563909774436
avg_envstep_per_sec: 185.98160734173516
avg_train_sample_per_sec: 185.98160734173516
avg_episode_per_sec: 7.677080625838229
reward_mean: 276.6917419433594
reward_std: 197.6239471435547
reward_max: 1262.0
reward_min: -50.0
total_envstep_count: 258874
total_train_sample_count: 251013
total_episode_count: 11297
[2024-05-28 08:44:01][sample_serial_collector.py:406][INFO] collect end:
episode_count: 134
envstep_count: 3274
train_sample_count: 3274
avg_envstep_per_episode: 24.432835820895523
avg_sample_per_episode: 24.432835820895523
avg_envstep_per_sec: 179.85211084252072
avg_train_sample_per_sec: 179.85211084252072
avg_episode_per_sec: 7.361082117561935
reward_mean: 280.6865539550781
reward_std: 206.03753662109375
reward_max: 1226.0
reward_min: -50.0
total_envstep_count: 262241
total_train_sample_count: 254287
total_episode_count: 11431
[2024-05-28 08:51:17][sample_serial_collector.py:406][INFO] collect end:
episode_count: 138
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 23.340579710144926
avg_sample_per_episode: 23.340579710144926
avg_envstep_per_sec: 186.59878043013586
avg_train_sample_per_sec: 186.59878043013586
avg_episode_per_sec: 7.994607792411905
reward_mean: 258.2029113769531
reward_std: 188.96641540527344
reward_max: 1268.0
reward_min: -50.0
total_envstep_count: 265571
total_train_sample_count: 257508
total_episode_count: 11569
[2024-05-28 08:58:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 135
envstep_count: 3239
train_sample_count: 3239
avg_envstep_per_episode: 23.992592592592594
avg_sample_per_episode: 23.992592592592594
avg_envstep_per_sec: 188.008425250756
avg_train_sample_per_sec: 188.008425250756
avg_episode_per_sec: 7.8361029357369745
reward_mean: 270.9333190917969
reward_std: 164.24349975585938
reward_max: 718.0
reward_min: -38.0
total_envstep_count: 268927
total_train_sample_count: 260747
total_episode_count: 11704
[2024-05-28 09:06:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 127
envstep_count: 3278
train_sample_count: 3278
avg_envstep_per_episode: 25.811023622047244
avg_sample_per_episode: 25.811023622047244
avg_envstep_per_sec: 188.94066111716242
avg_train_sample_per_sec: 188.94066111716242
avg_episode_per_sec: 7.320153740658824
reward_mean: 310.2992248535156
reward_std: 218.13963317871094
reward_max: 1280.0
reward_min: -38.0
total_envstep_count: 272368
total_train_sample_count: 264025
total_episode_count: 11831
[2024-05-28 09:13:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 139
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 23.172661870503596
avg_sample_per_episode: 23.172661870503596
avg_envstep_per_sec: 169.83972041213704
avg_train_sample_per_sec: 169.83972041213704
avg_episode_per_sec: 7.329314230762821
reward_mean: 267.16546630859375
reward_std: 210.21823120117188
reward_max: 1232.0
reward_min: -50.0
total_envstep_count: 275710
total_train_sample_count: 267246
total_episode_count: 11970
[2024-05-28 09:21:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 128
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 25.0078125
avg_sample_per_episode: 25.0078125
avg_envstep_per_sec: 186.8492627100209
avg_train_sample_per_sec: 186.8492627100209
avg_episode_per_sec: 7.471635622268877
reward_mean: 295.03125
reward_std: 200.82858276367188
reward_max: 1256.0
reward_min: -38.0
total_envstep_count: 278962
total_train_sample_count: 270447
total_episode_count: 12098
[2024-05-28 09:28:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 133
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 24.270676691729324
avg_sample_per_episode: 24.270676691729324
avg_envstep_per_sec: 187.31787403103615
avg_train_sample_per_sec: 187.31787403103615
avg_episode_per_sec: 7.717867796198206
reward_mean: 275.24810791015625
reward_std: 212.95538330078125
reward_max: 1274.0
reward_min: -38.0
total_envstep_count: 282264
total_train_sample_count: 273675
total_episode_count: 12231
[2024-05-28 09:36:07][sample_serial_collector.py:406][INFO] collect end:
episode_count: 131
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 24.450381679389313
avg_sample_per_episode: 24.450381679389313
avg_envstep_per_sec: 178.9599459412852
avg_train_sample_per_sec: 178.9599459412852
avg_episode_per_sec: 7.319310932971702
reward_mean: 275.5419921875
reward_std: 181.61424255371094
reward_max: 1202.0
reward_min: -50.0
total_envstep_count: 285532
total_train_sample_count: 276878
total_episode_count: 12362
[2024-05-28 09:43:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 140
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 22.857142857142858
avg_sample_per_episode: 22.857142857142858
avg_envstep_per_sec: 187.4438518125104
avg_train_sample_per_sec: 187.4438518125104
avg_episode_per_sec: 8.20066851679733
reward_mean: 247.75714111328125
reward_std: 185.76844787597656
reward_max: 1232.0
reward_min: -50.0
total_envstep_count: 288863
total_train_sample_count: 280078
total_episode_count: 12502
