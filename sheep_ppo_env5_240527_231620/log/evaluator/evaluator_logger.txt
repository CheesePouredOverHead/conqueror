[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: -38.0000, current episode: 1
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: -26.0000, current episode: 2
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: -26.0000, current episode: 3
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 4.0000, current episode: 4
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 46.0000, current episode: 5
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 76.0000, current episode: 6
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: -26.0000, current episode: 6
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 118.0000, current episode: 7
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: -26.0000, current episode: 7
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 16.0000, current episode: 7
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 220.0000, current episode: 8
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 190.0000, current episode: 9
[2024-05-27 23:16:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 196.0000, current episode: 10
[2024-05-27 23:16:48][interaction_serial_evaluator.py:285][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 10.000000     | 180.000000    |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 18.000000               | 0.893752      | 201.398075          | 11.188782            |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 77.200000   | 93.907188  | 220.000000 | -38.000000 |
+-------+-------------+------------+------------+------------+
+-------+-----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                     |
+-------+-----------------------------------------------------------------------------------------+
| Value | [[-26.0], [220.0], [-38.0], [46.0], [76.0], [-26.0], [190.0], [16.0], [196.0], [118.0]] |
+-------+-----------------------------------------------------------------------------------------+

[2024-05-27 23:53:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: -38.0000, current episode: 1
[2024-05-27 23:53:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 64.0000, current episode: 2
[2024-05-27 23:53:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 136.0000, current episode: 3
[2024-05-27 23:53:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 112.0000, current episode: 4
[2024-05-27 23:53:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 118.0000, current episode: 5
[2024-05-27 23:53:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 94.0000, current episode: 6
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 196.0000, current episode: 7
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 238.0000, current episode: 8
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 124.0000, current episode: 8
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 4.0000, current episode: 8
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 268.0000, current episode: 9
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 10.0000, current episode: 9
[2024-05-27 23:53:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 340.0000, current episode: 10
[2024-05-27 23:53:06][interaction_serial_evaluator.py:285][INFO] 
+-------+------------+-----------------------+---------------+---------------+
| Name  | train_iter | ckpt_name             | episode_count | envstep_count |
+-------+------------+-----------------------+---------------+---------------+
| Value | 500.000000 | iteration_500.pth.tar | 10.000000     | 302.000000    |
+-------+------------+-----------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.200000               | 1.570350      | 192.313765          | 6.368005             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 152.200000  | 103.055131 | 340.000000 | 4.000000   |
+-------+-------------+------------+------------+------------+
+-------+----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                    |
+-------+----------------------------------------------------------------------------------------+
| Value | [[196.0], [136.0], [124.0], [4.0], [112.0], [10.0], [238.0], [94.0], [268.0], [340.0]] |
+-------+----------------------------------------------------------------------------------------+

[2024-05-28 00:29:52][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: -50.0000, current episode: 1
[2024-05-28 00:29:52][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 4.0000, current episode: 2
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 34.0000, current episode: 3
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 40.0000, current episode: 4
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 106.0000, current episode: 5
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 178.0000, current episode: 6
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 148.0000, current episode: 7
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 4.0000, current episode: 7
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 202.0000, current episode: 8
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 268.0000, current episode: 9
[2024-05-28 00:29:53][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 244.0000, current episode: 10
[2024-05-28 00:29:53][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 1000.000000 | iteration_1000.pth.tar | 10.000000     | 241.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 24.100000               | 1.336006      | 180.388421          | 7.484997             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 117.400000  | 102.192172 | 268.000000 | -50.000000 |
+-------+-------------+------------+------------+------------+
+-------+----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                    |
+-------+----------------------------------------------------------------------------------------+
| Value | [[106.0], [-50.0], [34.0], [268.0], [40.0], [202.0], [244.0], [4.0], [178.0], [148.0]] |
+-------+----------------------------------------------------------------------------------------+

[2024-05-28 01:06:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: -50.0000, current episode: 1
[2024-05-28 01:06:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: -50.0000, current episode: 2
[2024-05-28 01:06:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 16.0000, current episode: 3
[2024-05-28 01:06:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 124.0000, current episode: 4
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 202.0000, current episode: 5
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 178.0000, current episode: 6
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 250.0000, current episode: 7
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 136.0000, current episode: 7
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 178.0000, current episode: 7
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 328.0000, current episode: 8
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 484.0000, current episode: 9
[2024-05-28 01:06:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 154.0000, current episode: 9
[2024-05-28 01:06:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 622.0000, current episode: 10
[2024-05-28 01:06:21][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 1500.000000 | iteration_1500.pth.tar | 10.000000     | 448.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 44.800000               | 2.249406      | 199.163682          | 4.445618             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 240.400000  | 183.509782 | 622.000000 | -50.000000 |
+-------+-------------+------------+------------+------------+
+-------+--------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                        |
+-------+--------------------------------------------------------------------------------------------+
| Value | [[154.0], [622.0], [178.0], [178.0], [136.0], [124.0], [250.0], [484.0], [328.0], [-50.0]] |
+-------+--------------------------------------------------------------------------------------------+

[2024-05-28 01:42:18][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 16.0000, current episode: 1
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.0000, current episode: 2
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 118.0000, current episode: 3
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 238.0000, current episode: 4
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 232.0000, current episode: 5
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 256.0000, current episode: 6
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 286.0000, current episode: 7
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 322.0000, current episode: 8
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 88.0000, current episode: 8
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 160.0000, current episode: 8
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 376.0000, current episode: 9
[2024-05-28 01:42:19][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 412.0000, current episode: 10
[2024-05-28 01:42:19][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2000.000000 | iteration_2000.pth.tar | 10.000000     | 300.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.000000               | 1.590679      | 188.598657          | 6.286622             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 248.800000  | 100.427885 | 412.000000 | 88.000000  |
+-------+-------------+------------+------------+------------+
+-------+-------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                       |
+-------+-------------------------------------------------------------------------------------------+
| Value | [[118.0], [88.0], [256.0], [376.0], [286.0], [322.0], [412.0], [238.0], [160.0], [232.0]] |
+-------+-------------------------------------------------------------------------------------------+

[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 4.0000, current episode: 1
[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 4.0000, current episode: 2
[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 172.0000, current episode: 3
[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 244.0000, current episode: 4
[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 274.0000, current episode: 5
[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 310.0000, current episode: 6
[2024-05-28 02:18:08][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 148.0000, current episode: 6
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 340.0000, current episode: 7
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 220.0000, current episode: 7
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 412.0000, current episode: 8
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 442.0000, current episode: 9
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 118.0000, current episode: 9
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: -26.0000, current episode: 9
[2024-05-28 02:18:09][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 460.0000, current episode: 10
[2024-05-28 02:18:09][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 2500.000000 | iteration_2500.pth.tar | 10.000000     | 357.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 35.700000               | 1.733083      | 205.991344          | 5.770066             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 263.200000  | 148.014053 | 460.000000 | -26.000000 |
+-------+-------------+------------+------------+------------+
+-------+--------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                        |
+-------+--------------------------------------------------------------------------------------------+
| Value | [[412.0], [118.0], [460.0], [442.0], [340.0], [274.0], [-26.0], [220.0], [148.0], [244.0]] |
+-------+--------------------------------------------------------------------------------------------+

[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 58.0000, current episode: 1
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 70.0000, current episode: 2
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.0000, current episode: 3
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 70.0000, current episode: 4
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 214.0000, current episode: 5
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 268.0000, current episode: 6
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 262.0000, current episode: 7
[2024-05-28 02:54:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 256.0000, current episode: 8
[2024-05-28 02:54:23][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 130.0000, current episode: 8
[2024-05-28 02:54:23][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 334.0000, current episode: 9
[2024-05-28 02:54:23][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 148.0000, current episode: 9
[2024-05-28 02:54:23][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 202.0000, current episode: 9
[2024-05-28 02:54:23][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 76.0000, current episode: 9
[2024-05-28 02:54:23][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 538.0000, current episode: 10
[2024-05-28 02:54:23][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 3000.000000 | iteration_3000.pth.tar | 10.000000     | 392.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 39.200000               | 1.872772      | 209.315392          | 5.339678             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 228.400000  | 132.522602 | 538.000000 | 70.000000  |
+-------+-------------+------------+------------+------------+
+-------+------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                      |
+-------+------------------------------------------------------------------------------------------+
| Value | [[202.0], [76.0], [268.0], [262.0], [538.0], [70.0], [256.0], [334.0], [130.0], [148.0]] |
+-------+------------------------------------------------------------------------------------------+

[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 64.0000, current episode: 1
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 70.0000, current episode: 2
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 106.0000, current episode: 3
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 112.0000, current episode: 4
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 136.0000, current episode: 5
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 196.0000, current episode: 6
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 208.0000, current episode: 7
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 10.0000, current episode: 7
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 4.0000, current episode: 7
[2024-05-28 03:30:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 316.0000, current episode: 8
[2024-05-28 03:30:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 400.0000, current episode: 9
[2024-05-28 03:30:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 412.0000, current episode: 10
[2024-05-28 03:30:21][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 3500.000000 | iteration_3500.pth.tar | 10.000000     | 330.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 33.000000               | 1.679252      | 196.516078          | 5.955033             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 181.600000  | 144.603734 | 412.000000 | 4.000000   |
+-------+-------------+------------+------------+------------+
+-------+---------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                   |
+-------+---------------------------------------------------------------------------------------+
| Value | [[64.0], [136.0], [196.0], [10.0], [316.0], [400.0], [208.0], [70.0], [4.0], [412.0]] |
+-------+---------------------------------------------------------------------------------------+

[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 64.0000, current episode: 1
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 76.0000, current episode: 2
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 106.0000, current episode: 3
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 112.0000, current episode: 4
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 274.0000, current episode: 5
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 382.0000, current episode: 6
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 340.0000, current episode: 7
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 322.0000, current episode: 8
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 376.0000, current episode: 9
[2024-05-28 04:06:35][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 430.0000, current episode: 10
[2024-05-28 04:06:35][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4000.000000 | iteration_4000.pth.tar | 10.000000     | 335.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 33.500000               | 1.651783      | 202.811175          | 6.054065             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 248.200000  | 135.712785 | 430.000000 | 64.000000  |
+-------+-------------+------------+------------+------------+
+-------+------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                      |
+-------+------------------------------------------------------------------------------------------+
| Value | [[64.0], [382.0], [106.0], [76.0], [112.0], [430.0], [340.0], [322.0], [274.0], [376.0]] |
+-------+------------------------------------------------------------------------------------------+

[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 64.0000, current episode: 1
[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 64.0000, current episode: 2
[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 88.0000, current episode: 3
[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 118.0000, current episode: 4
[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 148.0000, current episode: 5
[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 232.0000, current episode: 6
[2024-05-28 04:42:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 202.0000, current episode: 7
[2024-05-28 04:42:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 58.0000, current episode: 7
[2024-05-28 04:42:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 286.0000, current episode: 8
[2024-05-28 04:42:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 358.0000, current episode: 9
[2024-05-28 04:42:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 400.0000, current episode: 10
[2024-05-28 04:42:42][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 4500.000000 | iteration_4500.pth.tar | 10.000000     | 301.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.100000               | 1.544500      | 194.885062          | 6.474587             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 195.400000  | 115.675581 | 400.000000 | 58.000000  |
+-------+-------------+------------+------------+------------+
+-------+-----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                     |
+-------+-----------------------------------------------------------------------------------------+
| Value | [[286.0], [148.0], [64.0], [58.0], [88.0], [358.0], [118.0], [232.0], [400.0], [202.0]] |
+-------+-----------------------------------------------------------------------------------------+

[2024-05-28 05:19:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 118.0000, current episode: 1
[2024-05-28 05:19:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 94.0000, current episode: 2
[2024-05-28 05:19:05][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 178.0000, current episode: 3
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 286.0000, current episode: 4
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 316.0000, current episode: 5
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 436.0000, current episode: 6
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 412.0000, current episode: 7
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 190.0000, current episode: 7
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 64.0000, current episode: 7
[2024-05-28 05:19:06][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 538.0000, current episode: 8
[2024-05-28 05:19:07][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 334.0000, current episode: 8
[2024-05-28 05:19:07][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 538.0000, current episode: 9
[2024-05-28 05:19:07][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 112.0000, current episode: 9
[2024-05-28 05:19:07][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 352.0000, current episode: 9
[2024-05-28 05:19:07][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 754.0000, current episode: 10
[2024-05-28 05:19:07][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 5000.000000 | iteration_5000.pth.tar | 10.000000     | 536.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 53.600000               | 2.613772      | 205.067644          | 3.825889             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 373.000000  | 201.035818 | 754.000000 | 64.000000  |
+-------+-------------+------------+------------+------------+
+-------+-------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                       |
+-------+-------------------------------------------------------------------------------------------+
| Value | [[538.0], [436.0], [334.0], [754.0], [412.0], [64.0], [190.0], [538.0], [352.0], [112.0]] |
+-------+-------------------------------------------------------------------------------------------+

[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 52.0000, current episode: 1
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 88.0000, current episode: 2
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 118.0000, current episode: 3
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 112.0000, current episode: 4
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 94.0000, current episode: 5
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 178.0000, current episode: 6
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 160.0000, current episode: 7
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 208.0000, current episode: 8
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 58.0000, current episode: 8
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 274.0000, current episode: 9
[2024-05-28 05:55:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 58.0000, current episode: 9
[2024-05-28 05:55:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 418.0000, current episode: 10
[2024-05-28 05:55:21][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 5500.000000 | iteration_5500.pth.tar | 10.000000     | 363.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 36.300000               | 1.860178      | 195.142641          | 5.375830             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 164.800000  | 107.055873 | 418.000000 | 58.000000  |
+-------+-------------+------------+------------+------------+
+-------+----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                    |
+-------+----------------------------------------------------------------------------------------+
| Value | [[88.0], [418.0], [274.0], [208.0], [58.0], [178.0], [58.0], [160.0], [112.0], [94.0]] |
+-------+----------------------------------------------------------------------------------------+

[2024-05-28 06:31:43][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 4.0000, current episode: 1
[2024-05-28 06:31:43][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 58.0000, current episode: 2
[2024-05-28 06:31:43][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 118.0000, current episode: 3
[2024-05-28 06:31:43][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 142.0000, current episode: 4
[2024-05-28 06:31:43][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 220.0000, current episode: 5
[2024-05-28 06:31:43][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 244.0000, current episode: 6
[2024-05-28 06:31:44][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 268.0000, current episode: 7
[2024-05-28 06:31:44][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 76.0000, current episode: 7
[2024-05-28 06:31:44][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 322.0000, current episode: 8
[2024-05-28 06:31:44][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 364.0000, current episode: 9
[2024-05-28 06:31:44][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 340.0000, current episode: 10
[2024-05-28 06:31:44][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6000.000000 | iteration_6000.pth.tar | 10.000000     | 301.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 30.100000               | 1.589070      | 189.418987          | 6.292990             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 209.800000  | 114.568582 | 364.000000 | 4.000000   |
+-------+-------------+------------+------------+------------+
+-------+-----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                     |
+-------+-----------------------------------------------------------------------------------------+
| Value | [[142.0], [220.0], [364.0], [244.0], [268.0], [4.0], [76.0], [340.0], [118.0], [322.0]] |
+-------+-----------------------------------------------------------------------------------------+

[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.0000, current episode: 1
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 64.0000, current episode: 2
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 124.0000, current episode: 3
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 274.0000, current episode: 4
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 298.0000, current episode: 5
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 58.0000, current episode: 5
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 388.0000, current episode: 6
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 400.0000, current episode: 7
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 148.0000, current episode: 7
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 424.0000, current episode: 8
[2024-05-28 07:08:20][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 436.0000, current episode: 9
[2024-05-28 07:08:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 178.0000, current episode: 9
[2024-05-28 07:08:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 4.0000, current episode: 9
[2024-05-28 07:08:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 70.0000, current episode: 9
[2024-05-28 07:08:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 568.0000, current episode: 10
[2024-05-28 07:08:21][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 6500.000000 | iteration_6500.pth.tar | 10.000000     | 416.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 41.600000               | 2.118024      | 196.409518          | 4.721383             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 256.000000  | 182.778555 | 568.000000 | 4.000000   |
+-------+-------------+------------+------------+------------+
+-------+----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                    |
+-------+----------------------------------------------------------------------------------------+
| Value | [[274.0], [58.0], [424.0], [436.0], [568.0], [178.0], [4.0], [148.0], [70.0], [400.0]] |
+-------+----------------------------------------------------------------------------------------+

[2024-05-28 07:44:55][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 118.0000, current episode: 1
[2024-05-28 07:44:55][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 118.0000, current episode: 2
[2024-05-28 07:44:55][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 82.0000, current episode: 3
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 208.0000, current episode: 4
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 202.0000, current episode: 5
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 262.0000, current episode: 6
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 274.0000, current episode: 7
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 334.0000, current episode: 8
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 358.0000, current episode: 9
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 94.0000, current episode: 9
[2024-05-28 07:44:56][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 424.0000, current episode: 10
[2024-05-28 07:44:56][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 7000.000000 | iteration_7000.pth.tar | 10.000000     | 330.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 33.000000               | 1.746475      | 188.952008          | 5.725818             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 239.200000  | 105.736276 | 424.000000 | 94.000000  |
+-------+-------------+------------+------------+------------+
+-------+-------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                       |
+-------+-------------------------------------------------------------------------------------------+
| Value | [[118.0], [424.0], [118.0], [262.0], [334.0], [208.0], [202.0], [358.0], [94.0], [274.0]] |
+-------+-------------------------------------------------------------------------------------------+

[2024-05-28 08:21:40][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 82.0000, current episode: 1
[2024-05-28 08:21:40][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 136.0000, current episode: 2
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 160.0000, current episode: 3
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 202.0000, current episode: 4
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 268.0000, current episode: 5
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 292.0000, current episode: 6
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 112.0000, current episode: 6
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 124.0000, current episode: 6
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 448.0000, current episode: 7
[2024-05-28 08:21:41][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 376.0000, current episode: 8
[2024-05-28 08:21:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 454.0000, current episode: 9
[2024-05-28 08:21:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 262.0000, current episode: 9
[2024-05-28 08:21:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 178.0000, current episode: 9
[2024-05-28 08:21:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 58.0000, current episode: 9
[2024-05-28 08:21:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 202.0000, current episode: 9
[2024-05-28 08:21:42][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 652.0000, current episode: 10
[2024-05-28 08:21:42][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 7500.000000 | iteration_7500.pth.tar | 10.000000     | 475.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 47.500000               | 2.372985      | 200.169838          | 4.214102             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 269.200000  | 179.013296 | 652.000000 | 58.000000  |
+-------+-------------+------------+------------+------------+
+-------+-------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                       |
+-------+-------------------------------------------------------------------------------------------+
| Value | [[448.0], [454.0], [58.0], [124.0], [202.0], [202.0], [652.0], [262.0], [112.0], [178.0]] |
+-------+-------------------------------------------------------------------------------------------+

[2024-05-28 08:58:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 16.0000, current episode: 1
[2024-05-28 08:58:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 166.0000, current episode: 2
[2024-05-28 08:58:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 220.0000, current episode: 3
[2024-05-28 08:58:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 58.0000, current episode: 3
[2024-05-28 08:58:21][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 292.0000, current episode: 4
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 274.0000, current episode: 5
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 286.0000, current episode: 6
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 322.0000, current episode: 7
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 298.0000, current episode: 8
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 442.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 124.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 4.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 118.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 172.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 124.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 178.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 202.0000, current episode: 9
[2024-05-28 08:58:22][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 640.0000, current episode: 10
[2024-05-28 08:58:22][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8000.000000 | iteration_8000.pth.tar | 10.000000     | 477.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 47.700000               | 2.416364      | 197.404057          | 4.138450             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 227.800000  | 175.463842 | 640.000000 | 4.000000   |
+-------+-------------+------------+------------+------------+
+-------+------------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                      |
+-------+------------------------------------------------------------------------------------------+
| Value | [[118.0], [640.0], [442.0], [274.0], [4.0], [172.0], [178.0], [124.0], [202.0], [124.0]] |
+-------+------------------------------------------------------------------------------------------+

[2024-05-28 09:35:47][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 10.0000, current episode: 1
[2024-05-28 09:35:47][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: 58.0000, current episode: 2
[2024-05-28 09:35:47][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 52.0000, current episode: 3
[2024-05-28 09:35:47][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 58.0000, current episode: 4
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 178.0000, current episode: 5
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 178.0000, current episode: 6
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 2 finish episode, final reward: -38.0000, current episode: 6
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 3 finish episode, final reward: 208.0000, current episode: 7
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 226.0000, current episode: 8
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 5 finish episode, final reward: 40.0000, current episode: 8
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 304.0000, current episode: 9
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 8 finish episode, final reward: 196.0000, current episode: 9
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 70.0000, current episode: 9
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 1 finish episode, final reward: 172.0000, current episode: 9
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 4 finish episode, final reward: 16.0000, current episode: 9
[2024-05-28 09:35:48][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 9 finish episode, final reward: 280.0000, current episode: 9
[2024-05-28 09:35:49][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 7 finish episode, final reward: 172.0000, current episode: 9
[2024-05-28 09:35:49][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 0 finish episode, final reward: 4.0000, current episode: 9
[2024-05-28 09:35:49][interaction_serial_evaluator.py:259][INFO] [EVALUATOR]env 6 finish episode, final reward: 592.0000, current episode: 10
[2024-05-28 09:35:49][interaction_serial_evaluator.py:285][INFO] 
+-------+-------------+------------------------+---------------+---------------+
| Name  | train_iter  | ckpt_name              | episode_count | envstep_count |
+-------+-------------+------------------------+---------------+---------------+
| Value | 8500.000000 | iteration_8500.pth.tar | 10.000000     | 444.000000    |
+-------+-------------+------------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 44.400000               | 2.310795      | 192.141680          | 4.327515             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | 164.200000  | 174.187141 | 592.000000 | -38.000000 |
+-------+-------------+------------+------------+------------+
+-------+----------------------------------------------------------------------------------------+
| Name  | eval_episode_return                                                                    |
+-------+----------------------------------------------------------------------------------------+
| Value | [[4.0], [172.0], [-38.0], [208.0], [16.0], [40.0], [592.0], [172.0], [196.0], [280.0]] |
+-------+----------------------------------------------------------------------------------------+

