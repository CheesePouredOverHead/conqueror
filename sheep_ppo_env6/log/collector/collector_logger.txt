[2024-06-01 00:57:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 685
envstep_count: 6403
train_sample_count: 6403
avg_envstep_per_episode: 9.347445255474453
avg_sample_per_episode: 9.347445255474453
avg_envstep_per_sec: 32.00856581232123
avg_train_sample_per_sec: 32.00856581232123
avg_episode_per_sec: 3.4243116635077375
reward_mean: 56.56438064575195
reward_std: 55.09104919433594
reward_max: 362.6000061035156
reward_min: -17.0
total_envstep_count: 6462
total_train_sample_count: 6403
total_episode_count: 685
[2024-06-01 01:05:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 294
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 10.96938775510204
avg_sample_per_episode: 10.96938775510204
avg_envstep_per_sec: 33.02538545045373
avg_train_sample_per_sec: 33.02538545045373
avg_episode_per_sec: 3.0106863015297356
reward_mean: 81.03877258300781
reward_std: 76.01697540283203
reward_max: 605.5999755859375
reward_min: -17.0
total_envstep_count: 9701
total_train_sample_count: 9628
total_episode_count: 979
[2024-06-01 01:13:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 287
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 11.177700348432056
avg_sample_per_episode: 11.177700348432056
avg_envstep_per_sec: 33.81736019246496
avg_train_sample_per_sec: 33.81736019246496
avg_episode_per_sec: 3.0254309149742653
reward_mean: 82.73797607421875
reward_std: 94.13982391357422
reward_max: 601.5999755859375
reward_min: -17.200000762939453
total_envstep_count: 12939
total_train_sample_count: 12836
total_episode_count: 1266
[2024-06-01 01:22:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 247
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 12.995951417004049
avg_sample_per_episode: 12.995951417004049
avg_envstep_per_sec: 34.47077888292746
avg_train_sample_per_sec: 34.47077888292746
avg_episode_per_sec: 2.6524244187174717
reward_mean: 113.42671966552734
reward_std: 129.36061096191406
reward_max: 623.5999755859375
reward_min: -17.0
total_envstep_count: 16189
total_train_sample_count: 16046
total_episode_count: 1513
[2024-06-01 01:30:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 260
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 12.326923076923077
avg_sample_per_episode: 12.326923076923077
avg_envstep_per_sec: 34.069046883270246
avg_train_sample_per_sec: 34.069046883270246
avg_episode_per_sec: 2.7637916348362754
reward_mean: 99.0
reward_std: 103.4498519897461
reward_max: 611.4000244140625
reward_min: -16.200000762939453
total_envstep_count: 19434
total_train_sample_count: 19251
total_episode_count: 1773
[2024-06-01 01:39:03][sample_serial_collector.py:406][INFO] collect end:
episode_count: 259
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 12.366795366795367
avg_sample_per_episode: 12.366795366795367
avg_envstep_per_sec: 34.492616001947255
avg_train_sample_per_sec: 34.492616001947255
avg_episode_per_sec: 2.789131297066606
reward_mean: 96.0687255859375
reward_std: 99.95112609863281
reward_max: 590.2000122070312
reward_min: -17.0
total_envstep_count: 22704
total_train_sample_count: 22454
total_episode_count: 2032
[2024-06-01 01:47:22][sample_serial_collector.py:406][INFO] collect end:
episode_count: 254
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 12.62992125984252
avg_sample_per_episode: 12.62992125984252
avg_envstep_per_sec: 34.6750959440455
avg_train_sample_per_sec: 34.6750959440455
avg_episode_per_sec: 2.7454720604075926
reward_mean: 102.70156860351562
reward_std: 107.88943481445312
reward_max: 597.0
reward_min: -19.200000762939453
total_envstep_count: 25974
total_train_sample_count: 25662
total_episode_count: 2286
[2024-06-01 01:55:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 241
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 13.356846473029046
avg_sample_per_episode: 13.356846473029046
avg_envstep_per_sec: 35.46160487548891
avg_train_sample_per_sec: 35.46160487548891
avg_episode_per_sec: 2.65493842031464
reward_mean: 113.23735046386719
reward_std: 119.1022720336914
reward_max: 604.4000244140625
reward_min: -17.0
total_envstep_count: 29239
total_train_sample_count: 28881
total_episode_count: 2527
[2024-06-01 02:03:51][sample_serial_collector.py:406][INFO] collect end:
episode_count: 205
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 15.609756097560975
avg_sample_per_episode: 15.609756097560975
avg_envstep_per_sec: 36.083990807219195
avg_train_sample_per_sec: 36.083990807219195
avg_episode_per_sec: 2.3116306610874795
reward_mean: 150.12098693847656
reward_std: 150.0955810546875
reward_max: 615.7999877929688
reward_min: -16.200000762939453
total_envstep_count: 32503
total_train_sample_count: 32081
total_episode_count: 2732
[2024-06-01 02:14:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 213
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 15.154929577464788
avg_sample_per_episode: 15.154929577464788
avg_envstep_per_sec: 14.683077747194211
avg_train_sample_per_sec: 14.683077747194211
avg_episode_per_sec: 0.9688647955862351
reward_mean: 145.93707275390625
reward_std: 151.30738830566406
reward_max: 608.2000122070312
reward_min: -17.0
total_envstep_count: 35808
total_train_sample_count: 35309
total_episode_count: 2945
[2024-06-01 02:23:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 215
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 14.948837209302326
avg_sample_per_episode: 14.948837209302326
avg_envstep_per_sec: 35.56803798797473
avg_train_sample_per_sec: 35.56803798797473
avg_episode_per_sec: 2.379318035909946
reward_mean: 138.0269775390625
reward_std: 141.129638671875
reward_max: 604.4000244140625
reward_min: -17.0
total_envstep_count: 39070
total_train_sample_count: 38523
total_episode_count: 3160
[2024-06-01 02:31:48][sample_serial_collector.py:406][INFO] collect end:
episode_count: 184
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 17.554347826086957
avg_sample_per_episode: 17.554347826086957
avg_envstep_per_sec: 37.993087976305475
avg_train_sample_per_sec: 37.993087976305475
avg_episode_per_sec: 2.1643121323963492
reward_mean: 182.8173828125
reward_std: 169.3495635986328
reward_max: 604.2000122070312
reward_min: -17.0
total_envstep_count: 42357
total_train_sample_count: 41753
total_episode_count: 3344
[2024-06-01 02:40:02][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 17.0531914893617
avg_sample_per_episode: 17.0531914893617
avg_envstep_per_sec: 37.1393290472466
avg_train_sample_per_sec: 37.1393290472466
avg_episode_per_sec: 2.1778521088216967
reward_mean: 172.17127990722656
reward_std: 150.55604553222656
reward_max: 599.7999877929688
reward_min: -17.0
total_envstep_count: 45639
total_train_sample_count: 44959
total_episode_count: 3532
[2024-06-01 02:48:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 16.95767195767196
avg_sample_per_episode: 16.95767195767196
avg_envstep_per_sec: 37.751410213733124
avg_train_sample_per_sec: 37.751410213733124
avg_episode_per_sec: 2.2262142060516568
reward_mean: 177.24020385742188
reward_std: 174.765869140625
reward_max: 617.2000122070312
reward_min: -17.0
total_envstep_count: 48901
total_train_sample_count: 48164
total_episode_count: 3721
[2024-06-01 02:56:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 174
envstep_count: 3240
train_sample_count: 3240
avg_envstep_per_episode: 18.620689655172413
avg_sample_per_episode: 18.620689655172413
avg_envstep_per_sec: 38.246800802978925
avg_train_sample_per_sec: 38.246800802978925
avg_episode_per_sec: 2.053994857937757
reward_mean: 204.92874145507812
reward_std: 184.15475463867188
reward_max: 604.7999877929688
reward_min: -17.0
total_envstep_count: 52200
total_train_sample_count: 51404
total_episode_count: 3895
[2024-06-01 03:04:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 184
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 17.440217391304348
avg_sample_per_episode: 17.440217391304348
avg_envstep_per_sec: 37.94349375806103
avg_train_sample_per_sec: 37.94349375806103
avg_episode_per_sec: 2.1756319262958024
reward_mean: 180.07064819335938
reward_std: 169.23545837402344
reward_max: 637.0
reward_min: -17.0
total_envstep_count: 55473
total_train_sample_count: 54613
total_episode_count: 4079
[2024-06-01 03:12:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 174
envstep_count: 3226
train_sample_count: 3226
avg_envstep_per_episode: 18.54022988505747
avg_sample_per_episode: 18.54022988505747
avg_envstep_per_sec: 38.72260689811464
avg_train_sample_per_sec: 38.72260689811464
avg_episode_per_sec: 2.0885721017581984
reward_mean: 200.2172393798828
reward_std: 175.70523071289062
reward_max: 598.4000244140625
reward_min: -16.200000762939453
total_envstep_count: 58772
total_train_sample_count: 57839
total_episode_count: 4253
[2024-06-01 03:21:03][sample_serial_collector.py:406][INFO] collect end:
episode_count: 165
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 19.454545454545453
avg_sample_per_episode: 19.454545454545453
avg_envstep_per_sec: 38.719156248526495
avg_train_sample_per_sec: 38.719156248526495
avg_episode_per_sec: 1.990237003428932
reward_mean: 218.71755981445312
reward_std: 186.67176818847656
reward_max: 611.7999877929688
reward_min: -17.0
total_envstep_count: 62045
total_train_sample_count: 61049
total_episode_count: 4418
[2024-06-01 03:29:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 159
envstep_count: 3234
train_sample_count: 3234
avg_envstep_per_episode: 20.339622641509433
avg_sample_per_episode: 20.339622641509433
avg_envstep_per_sec: 39.12425115961202
avg_train_sample_per_sec: 39.12425115961202
avg_episode_per_sec: 1.9235485264002201
reward_mean: 237.15975952148438
reward_std: 195.53500366210938
reward_max: 608.7999877929688
reward_min: -16.200000762939453
total_envstep_count: 65333
total_train_sample_count: 64283
total_episode_count: 4577
