[2024-06-01 11:28:50][sample_serial_collector.py:406][INFO] collect end:
episode_count: 734
envstep_count: 6425
train_sample_count: 6425
avg_envstep_per_episode: 8.753405994550409
avg_sample_per_episode: 8.753405994550409
avg_envstep_per_sec: 57.00590902429222
avg_train_sample_per_sec: 57.00590902429222
avg_episode_per_sec: 6.512426027055329
reward_mean: 39.34714126586914
reward_std: 67.28533172607422
reward_max: 431.0
reward_min: -29.0
total_envstep_count: 6483
total_train_sample_count: 6425
total_episode_count: 734
[2024-06-01 11:37:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 312
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 10.26602564102564
avg_sample_per_episode: 10.26602564102564
avg_envstep_per_sec: 57.622235676953665
avg_train_sample_per_sec: 57.622235676953665
avg_episode_per_sec: 5.612905879241193
reward_mean: 66.94615173339844
reward_std: 101.82928466796875
reward_max: 439.79998779296875
reward_min: -25.399999618530273
total_envstep_count: 9726
total_train_sample_count: 9628
total_episode_count: 1046
[2024-06-01 11:46:11][sample_serial_collector.py:406][INFO] collect end:
episode_count: 293
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 10.941979522184301
avg_sample_per_episode: 10.941979522184301
avg_envstep_per_sec: 62.559795903744146
avg_train_sample_per_sec: 62.559795903744146
avg_episode_per_sec: 5.717411166499387
reward_mean: 79.25050354003906
reward_std: 112.10124969482422
reward_max: 412.3999938964844
reward_min: -33.0
total_envstep_count: 12953
total_train_sample_count: 12834
total_episode_count: 1339
[2024-06-01 11:54:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 272
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 11.786764705882353
avg_sample_per_episode: 11.786764705882353
avg_envstep_per_sec: 64.35118758698293
avg_train_sample_per_sec: 64.35118758698293
avg_episode_per_sec: 5.459614168327934
reward_mean: 95.46617889404297
reward_std: 127.53782653808594
reward_max: 419.20001220703125
reward_min: -31.0
total_envstep_count: 16209
total_train_sample_count: 16040
total_episode_count: 1611
[2024-06-01 12:02:57][sample_serial_collector.py:406][INFO] collect end:
episode_count: 249
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 12.91566265060241
avg_sample_per_episode: 12.91566265060241
avg_envstep_per_sec: 63.34969100038323
avg_train_sample_per_sec: 63.34969100038323
avg_episode_per_sec: 4.904873463649075
reward_mean: 122.39678955078125
reward_std: 143.13070678710938
reward_max: 419.6000061035156
reward_min: -29.799999237060547
total_envstep_count: 19475
total_train_sample_count: 19256
total_episode_count: 1860
[2024-06-01 12:11:02][sample_serial_collector.py:406][INFO] collect end:
episode_count: 239
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 13.518828451882845
avg_sample_per_episode: 13.518828451882845
avg_envstep_per_sec: 67.68557315466994
avg_train_sample_per_sec: 67.68557315466994
avg_episode_per_sec: 5.0067632262352575
reward_mean: 138.1606903076172
reward_std: 159.3248748779297
reward_max: 421.6000061035156
reward_min: -26.600000381469727
total_envstep_count: 22753
total_train_sample_count: 22487
total_episode_count: 2099
[2024-06-01 12:19:09][sample_serial_collector.py:406][INFO] collect end:
episode_count: 237
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 13.603375527426161
avg_sample_per_episode: 13.603375527426161
avg_envstep_per_sec: 67.6654825441073
avg_train_sample_per_sec: 67.6654825441073
avg_episode_per_sec: 4.974168536896225
reward_mean: 136.484375
reward_std: 156.80496215820312
reward_max: 416.3999938964844
reward_min: -29.0
total_envstep_count: 26049
total_train_sample_count: 25711
total_episode_count: 2336
[2024-06-01 12:27:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 228
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 14.131578947368421
avg_sample_per_episode: 14.131578947368421
avg_envstep_per_sec: 67.81869377389691
avg_train_sample_per_sec: 67.81869377389691
avg_episode_per_sec: 4.799088200015052
reward_mean: 150.11842346191406
reward_std: 160.2962646484375
reward_max: 411.6000061035156
reward_min: -38.0
total_envstep_count: 29352
total_train_sample_count: 28933
total_episode_count: 2564
[2024-06-01 12:35:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 213
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 15.19718309859155
avg_sample_per_episode: 15.19718309859155
avg_envstep_per_sec: 69.23922017658137
avg_train_sample_per_sec: 69.23922017658137
avg_episode_per_sec: 4.556056193269024
reward_mean: 173.1737060546875
reward_std: 163.23519897460938
reward_max: 417.20001220703125
reward_min: -17.0
total_envstep_count: 32628
total_train_sample_count: 32170
total_episode_count: 2777
[2024-06-01 12:43:35][sample_serial_collector.py:406][INFO] collect end:
episode_count: 217
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 14.838709677419354
avg_sample_per_episode: 14.838709677419354
avg_envstep_per_sec: 69.30008054407233
avg_train_sample_per_sec: 69.30008054407233
avg_episode_per_sec: 4.67022281927444
reward_mean: 157.6285858154297
reward_std: 158.80355834960938
reward_max: 418.20001220703125
reward_min: -38.0
total_envstep_count: 35914
total_train_sample_count: 35390
total_episode_count: 2994
[2024-06-01 12:51:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 210
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 15.323809523809524
avg_sample_per_episode: 15.323809523809524
avg_envstep_per_sec: 70.96022846579001
avg_train_sample_per_sec: 70.96022846579001
avg_episode_per_sec: 4.630717208768149
reward_mean: 176.36093139648438
reward_std: 166.7806854248047
reward_max: 420.79998779296875
reward_min: -23.399999618530273
total_envstep_count: 39212
total_train_sample_count: 38608
total_episode_count: 3204
[2024-06-01 12:59:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 216
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 14.842592592592593
avg_sample_per_episode: 14.842592592592593
avg_envstep_per_sec: 69.38139894918791
avg_train_sample_per_sec: 69.38139894918791
avg_episode_per_sec: 4.674479779483653
reward_mean: 160.4583282470703
reward_std: 162.6879119873047
reward_max: 435.20001220703125
reward_min: -38.0
total_envstep_count: 42479
total_train_sample_count: 41814
total_episode_count: 3420
[2024-06-01 13:08:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 209
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 15.339712918660288
avg_sample_per_episode: 15.339712918660288
avg_envstep_per_sec: 69.98944840750184
avg_train_sample_per_sec: 69.98944840750184
avg_episode_per_sec: 4.562630916147188
reward_mean: 170.51100158691406
reward_std: 165.36892700195312
reward_max: 410.0
reward_min: -31.0
total_envstep_count: 45753
total_train_sample_count: 45020
total_episode_count: 3629
[2024-06-01 13:16:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 208
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 15.5625
avg_sample_per_episode: 15.5625
avg_envstep_per_sec: 72.62508601393847
avg_train_sample_per_sec: 72.62508601393847
avg_episode_per_sec: 4.666672193666729
reward_mean: 176.97979736328125
reward_std: 162.06373596191406
reward_max: 422.0
reward_min: -18.0
total_envstep_count: 49019
total_train_sample_count: 48257
total_episode_count: 3837
[2024-06-01 13:24:22][sample_serial_collector.py:406][INFO] collect end:
episode_count: 202
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 15.881188118811881
avg_sample_per_episode: 15.881188118811881
avg_envstep_per_sec: 70.91233665032966
avg_train_sample_per_sec: 70.91233665032966
avg_episode_per_sec: 4.4651783052888385
reward_mean: 182.9336700439453
reward_std: 168.1388397216797
reward_max: 416.20001220703125
reward_min: -31.0
total_envstep_count: 52302
total_train_sample_count: 51465
total_episode_count: 4039
[2024-06-01 13:32:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 16.708333333333332
avg_sample_per_episode: 16.708333333333332
avg_envstep_per_sec: 70.195605742741
avg_train_sample_per_sec: 70.195605742741
avg_episode_per_sec: 4.201233261410932
reward_mean: 203.9552001953125
reward_std: 162.31886291503906
reward_max: 412.20001220703125
reward_min: -27.0
total_envstep_count: 55589
total_train_sample_count: 54673
total_episode_count: 4231
[2024-06-01 13:40:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 208
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 15.39423076923077
avg_sample_per_episode: 15.39423076923077
avg_envstep_per_sec: 70.33522888197328
avg_train_sample_per_sec: 70.33522888197328
avg_episode_per_sec: 4.568934293394891
reward_mean: 177.7538299560547
reward_std: 171.03021240234375
reward_max: 413.20001220703125
reward_min: -29.799999237060547
total_envstep_count: 58840
total_train_sample_count: 57875
total_episode_count: 4439
[2024-06-01 13:49:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 16.666666666666668
avg_sample_per_episode: 16.666666666666668
avg_envstep_per_sec: 71.51185603805905
avg_train_sample_per_sec: 71.51185603805905
avg_episode_per_sec: 4.290711362283543
reward_mean: 202.8656005859375
reward_std: 168.38987731933594
reward_max: 421.3999938964844
reward_min: -33.0
total_envstep_count: 62096
total_train_sample_count: 61075
total_episode_count: 4631
[2024-06-01 13:58:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 201
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 15.970149253731343
avg_sample_per_episode: 15.970149253731343
avg_envstep_per_sec: 72.07529811122075
avg_train_sample_per_sec: 72.07529811122075
avg_episode_per_sec: 4.5131261434128875
reward_mean: 184.22486877441406
reward_std: 163.5137481689453
reward_max: 413.3999938964844
reward_min: -20.200000762939453
total_envstep_count: 65351
total_train_sample_count: 64285
total_episode_count: 4832
[2024-06-01 14:06:46][sample_serial_collector.py:406][INFO] collect end:
episode_count: 199
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 16.170854271356784
avg_sample_per_episode: 16.170854271356784
avg_envstep_per_sec: 69.29279499992839
avg_train_sample_per_sec: 69.29279499992839
avg_episode_per_sec: 4.28504232597444
reward_mean: 188.60096740722656
reward_std: 162.76861572265625
reward_max: 407.6000061035156
reward_min: -21.0
total_envstep_count: 68615
total_train_sample_count: 67503
total_episode_count: 5031
[2024-06-01 14:15:11][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 17.128342245989305
avg_sample_per_episode: 17.128342245989305
avg_envstep_per_sec: 71.04441698662048
avg_train_sample_per_sec: 71.04441698662048
avg_episode_per_sec: 4.147769583670942
reward_mean: 212.75186157226562
reward_std: 167.60690307617188
reward_max: 433.79998779296875
reward_min: -21.0
total_envstep_count: 71871
total_train_sample_count: 70706
total_episode_count: 5218
[2024-06-01 14:23:51][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 16.853403141361255
avg_sample_per_episode: 16.853403141361255
avg_envstep_per_sec: 70.7154859633731
avg_train_sample_per_sec: 70.7154859633731
avg_episode_per_sec: 4.195917309414185
reward_mean: 210.02828979492188
reward_std: 170.40707397460938
reward_max: 422.20001220703125
reward_min: -29.0
total_envstep_count: 75158
total_train_sample_count: 73925
total_episode_count: 5409
[2024-06-01 14:32:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 201
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 15.945273631840797
avg_sample_per_episode: 15.945273631840797
avg_envstep_per_sec: 72.17652209132763
avg_train_sample_per_sec: 72.17652209132763
avg_episode_per_sec: 4.526515113995898
reward_mean: 185.26866149902344
reward_std: 164.7144775390625
reward_max: 438.6000061035156
reward_min: -29.0
total_envstep_count: 78409
total_train_sample_count: 77130
total_episode_count: 5610
[2024-06-01 14:41:25][sample_serial_collector.py:406][INFO] collect end:
episode_count: 195
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 16.456410256410255
avg_sample_per_episode: 16.456410256410255
avg_envstep_per_sec: 71.96931352056603
avg_train_sample_per_sec: 71.96931352056603
avg_episode_per_sec: 4.373330051888556
reward_mean: 195.994873046875
reward_std: 168.9004364013672
reward_max: 423.3999938964844
reward_min: -29.0
total_envstep_count: 81681
total_train_sample_count: 80339
total_episode_count: 5805
[2024-06-01 14:50:18][sample_serial_collector.py:406][INFO] collect end:
episode_count: 195
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 16.497435897435896
avg_sample_per_episode: 16.497435897435896
avg_envstep_per_sec: 71.8579044943295
avg_train_sample_per_sec: 71.8579044943295
avg_episode_per_sec: 4.355701391480961
reward_mean: 199.00205993652344
reward_std: 168.1113739013672
reward_max: 427.3999938964844
reward_min: -17.0
total_envstep_count: 84995
total_train_sample_count: 83556
total_episode_count: 6000
[2024-06-01 14:59:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 201
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 15.975124378109452
avg_sample_per_episode: 15.975124378109452
avg_envstep_per_sec: 69.12572728946121
avg_train_sample_per_sec: 69.12572728946121
avg_episode_per_sec: 4.327085389343414
reward_mean: 185.08856201171875
reward_std: 164.69705200195312
reward_max: 424.20001220703125
reward_min: -29.0
total_envstep_count: 88274
total_train_sample_count: 86767
total_episode_count: 6201
[2024-06-01 15:07:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 193
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 16.59585492227979
avg_sample_per_episode: 16.59585492227979
avg_envstep_per_sec: 69.4262559499435
avg_train_sample_per_sec: 69.4262559499435
avg_episode_per_sec: 4.183349172132093
reward_mean: 199.86322021484375
reward_std: 165.81671142578125
reward_max: 408.0
reward_min: -22.600000381469727
total_envstep_count: 91556
total_train_sample_count: 89970
total_episode_count: 6394
[2024-06-01 15:15:57][sample_serial_collector.py:406][INFO] collect end:
episode_count: 200
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 16.01
avg_sample_per_episode: 16.01
avg_envstep_per_sec: 72.22775796670155
avg_train_sample_per_sec: 72.22775796670155
avg_episode_per_sec: 4.511415238394849
reward_mean: 187.8839874267578
reward_std: 166.3362274169922
reward_max: 411.3999938964844
reward_min: -29.0
total_envstep_count: 94818
total_train_sample_count: 93172
total_episode_count: 6594
[2024-06-01 15:24:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 16.536082474226806
avg_sample_per_episode: 16.536082474226806
avg_envstep_per_sec: 68.02369439451161
avg_train_sample_per_sec: 68.02369439451161
avg_episode_per_sec: 4.113652341812735
reward_mean: 197.68556213378906
reward_std: 169.1907196044922
reward_max: 404.20001220703125
reward_min: -31.0
total_envstep_count: 98054
total_train_sample_count: 96380
total_episode_count: 6788
[2024-06-01 15:33:03][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 17.02659574468085
avg_sample_per_episode: 17.02659574468085
avg_envstep_per_sec: 68.66453395727503
avg_train_sample_per_sec: 68.66453395727503
avg_episode_per_sec: 4.032781125888068
reward_mean: 208.04359436035156
reward_std: 172.3970489501953
reward_max: 419.6000061035156
reward_min: -29.0
total_envstep_count: 101305
total_train_sample_count: 99581
total_episode_count: 6976
[2024-06-01 15:41:41][sample_serial_collector.py:406][INFO] collect end:
episode_count: 184
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 17.434782608695652
avg_sample_per_episode: 17.434782608695652
avg_envstep_per_sec: 68.94949533524479
avg_train_sample_per_sec: 68.94949533524479
avg_episode_per_sec: 3.954709208754689
reward_mean: 218.3684844970703
reward_std: 167.64151000976562
reward_max: 426.20001220703125
reward_min: -27.0
total_envstep_count: 104614
total_train_sample_count: 102789
total_episode_count: 7160
[2024-06-01 15:51:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 16.675257731958762
avg_sample_per_episode: 16.675257731958762
avg_envstep_per_sec: 70.30129655431296
avg_train_sample_per_sec: 70.30129655431296
avg_episode_per_sec: 4.21590464653376
reward_mean: 207.87318420410156
reward_std: 167.5152130126953
reward_max: 408.0
reward_min: -31.0
total_envstep_count: 107903
total_train_sample_count: 106024
total_episode_count: 7354
[2024-06-01 15:59:19][sample_serial_collector.py:406][INFO] collect end:
episode_count: 196
envstep_count: 3255
train_sample_count: 3255
avg_envstep_per_episode: 16.607142857142858
avg_sample_per_episode: 16.607142857142858
avg_envstep_per_sec: 70.29589899730682
avg_train_sample_per_sec: 70.29589899730682
avg_episode_per_sec: 4.232871337472239
reward_mean: 199.48367309570312
reward_std: 167.5242462158203
reward_max: 407.6000061035156
reward_min: -23.799999237060547
total_envstep_count: 111194
total_train_sample_count: 109279
total_episode_count: 7550
[2024-06-01 16:07:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 16.82198952879581
avg_sample_per_episode: 16.82198952879581
avg_envstep_per_sec: 72.64553019278397
avg_train_sample_per_sec: 72.64553019278397
avg_episode_per_sec: 4.3184862330599865
reward_mean: 199.344482421875
reward_std: 165.6494598388672
reward_max: 413.3999938964844
reward_min: -26.600000381469727
total_envstep_count: 114441
total_train_sample_count: 112492
total_episode_count: 7741
[2024-06-01 16:15:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 17.288770053475936
avg_sample_per_episode: 17.288770053475936
avg_envstep_per_sec: 72.65593903955417
avg_train_sample_per_sec: 72.65593903955417
avg_episode_per_sec: 4.202493226228466
reward_mean: 213.16258239746094
reward_std: 166.05093383789062
reward_max: 442.79998779296875
reward_min: -29.0
total_envstep_count: 117722
total_train_sample_count: 115725
total_episode_count: 7928
[2024-06-01 16:23:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 193
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 16.6580310880829
avg_sample_per_episode: 16.6580310880829
avg_envstep_per_sec: 70.70080130559808
avg_train_sample_per_sec: 70.70080130559808
avg_episode_per_sec: 4.244247170133882
reward_mean: 201.0165557861328
reward_std: 168.04188537597656
reward_max: 418.3999938964844
reward_min: -26.600000381469727
total_envstep_count: 121001
total_train_sample_count: 118940
total_episode_count: 8121
[2024-06-01 16:31:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 200
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 16.075
avg_sample_per_episode: 16.075
avg_envstep_per_sec: 72.38489531673554
avg_train_sample_per_sec: 72.38489531673554
avg_episode_per_sec: 4.502948386733159
reward_mean: 191.59300231933594
reward_std: 171.43215942382812
reward_max: 409.20001220703125
reward_min: -33.0
total_envstep_count: 124274
total_train_sample_count: 122155
total_episode_count: 8321
[2024-06-01 16:40:09][sample_serial_collector.py:406][INFO] collect end:
episode_count: 186
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 17.327956989247312
avg_sample_per_episode: 17.327956989247312
avg_envstep_per_sec: 70.94714938593525
avg_train_sample_per_sec: 70.94714938593525
avg_episode_per_sec: 4.094374739616493
reward_mean: 219.75054931640625
reward_std: 166.66571044921875
reward_max: 427.3999938964844
reward_min: -30.200000762939453
total_envstep_count: 127581
total_train_sample_count: 125378
total_episode_count: 8507
[2024-06-01 16:48:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 206
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 15.577669902912621
avg_sample_per_episode: 15.577669902912621
avg_envstep_per_sec: 71.37256842104306
avg_train_sample_per_sec: 71.37256842104306
avg_episode_per_sec: 4.581722996177896
reward_mean: 179.31454467773438
reward_std: 167.36947631835938
reward_max: 413.0
reward_min: -29.0
total_envstep_count: 130883
total_train_sample_count: 128587
total_episode_count: 8713
[2024-06-01 16:56:37][sample_serial_collector.py:406][INFO] collect end:
episode_count: 184
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 17.407608695652176
avg_sample_per_episode: 17.407608695652176
avg_envstep_per_sec: 71.88114681010578
avg_train_sample_per_sec: 71.88114681010578
avg_episode_per_sec: 4.129294727773794
reward_mean: 226.51519775390625
reward_std: 169.88182067871094
reward_max: 406.0
reward_min: -31.0
total_envstep_count: 134193
total_train_sample_count: 131790
total_episode_count: 8897
[2024-06-01 17:04:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 200
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 16.04
avg_sample_per_episode: 16.04
avg_envstep_per_sec: 71.57266388541993
avg_train_sample_per_sec: 71.57266388541993
avg_episode_per_sec: 4.462136152457601
reward_mean: 193.2050018310547
reward_std: 171.46798706054688
reward_max: 424.6000061035156
reward_min: -29.0
total_envstep_count: 137447
total_train_sample_count: 134998
total_episode_count: 9097
[2024-06-01 17:12:56][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 16.52577319587629
avg_sample_per_episode: 16.52577319587629
avg_envstep_per_sec: 69.96067430219765
avg_train_sample_per_sec: 69.96067430219765
avg_episode_per_sec: 4.233428201692559
reward_mean: 196.0453643798828
reward_std: 165.0572052001953
reward_max: 426.6000061035156
reward_min: -20.200000762939453
total_envstep_count: 140728
total_train_sample_count: 138204
total_episode_count: 9291
[2024-06-01 17:21:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 210
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 15.295238095238096
avg_sample_per_episode: 15.295238095238096
avg_envstep_per_sec: 71.00424383186864
avg_train_sample_per_sec: 71.00424383186864
avg_episode_per_sec: 4.642245082407352
reward_mean: 173.5257110595703
reward_std: 171.77943420410156
reward_max: 408.79998779296875
reward_min: -33.79999923706055
total_envstep_count: 144032
total_train_sample_count: 141416
total_episode_count: 9501
[2024-06-01 17:29:22][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 16.857894736842105
avg_sample_per_episode: 16.857894736842105
avg_envstep_per_sec: 71.9961523815217
avg_train_sample_per_sec: 71.9961523815217
avg_episode_per_sec: 4.270767702931352
reward_mean: 214.8326416015625
reward_std: 171.2278594970703
reward_max: 422.20001220703125
reward_min: -38.0
total_envstep_count: 147285
total_train_sample_count: 144619
total_episode_count: 9691
[2024-06-01 17:37:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 193
envstep_count: 3246
train_sample_count: 3246
avg_envstep_per_episode: 16.818652849740932
avg_sample_per_episode: 16.818652849740932
avg_envstep_per_sec: 70.71665309311368
avg_train_sample_per_sec: 70.71665309311368
avg_episode_per_sec: 4.204656206707005
reward_mean: 208.90879821777344
reward_std: 171.7042999267578
reward_max: 437.6000061035156
reward_min: -33.0
total_envstep_count: 150592
total_train_sample_count: 147865
total_episode_count: 9884
[2024-06-01 17:46:02][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 16.86842105263158
avg_sample_per_episode: 16.86842105263158
avg_envstep_per_sec: 71.57321774674301
avg_train_sample_per_sec: 71.57321774674301
avg_episode_per_sec: 4.243030069229695
reward_mean: 208.1105499267578
reward_std: 167.0217742919922
reward_max: 422.0
reward_min: -29.0
total_envstep_count: 153864
total_train_sample_count: 151070
total_episode_count: 10074
[2024-06-01 17:54:35][sample_serial_collector.py:406][INFO] collect end:
episode_count: 200
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 16.04
avg_sample_per_episode: 16.04
avg_envstep_per_sec: 68.69540559804715
avg_train_sample_per_sec: 68.69540559804715
avg_episode_per_sec: 4.282755959978002
reward_mean: 192.11500549316406
reward_std: 172.88619995117188
reward_max: 432.6000061035156
reward_min: -23.0
total_envstep_count: 157144
total_train_sample_count: 154278
total_episode_count: 10274
[2024-06-01 18:03:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 196
envstep_count: 3262
train_sample_count: 3262
avg_envstep_per_episode: 16.642857142857142
avg_sample_per_episode: 16.642857142857142
avg_envstep_per_sec: 72.88697714703642
avg_train_sample_per_sec: 72.88697714703642
avg_episode_per_sec: 4.379475021710342
reward_mean: 204.30612182617188
reward_std: 169.8657684326172
reward_max: 424.0
reward_min: -33.0
total_envstep_count: 160435
total_train_sample_count: 157540
total_episode_count: 10470
[2024-06-01 18:11:34][sample_serial_collector.py:406][INFO] collect end:
episode_count: 186
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 17.204301075268816
avg_sample_per_episode: 17.204301075268816
avg_envstep_per_sec: 72.04908099162024
avg_train_sample_per_sec: 72.04908099162024
avg_episode_per_sec: 4.187852832637926
reward_mean: 213.18173217773438
reward_std: 167.5748748779297
reward_max: 433.79998779296875
reward_min: -29.799999237060547
total_envstep_count: 163700
total_train_sample_count: 160740
total_episode_count: 10656
[2024-06-01 18:19:48][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 17.138297872340427
avg_sample_per_episode: 17.138297872340427
avg_envstep_per_sec: 73.411912288065
avg_train_sample_per_sec: 73.411912288065
avg_episode_per_sec: 4.283500779067728
reward_mean: 215.4042510986328
reward_std: 169.2127685546875
reward_max: 420.3999938964844
reward_min: -29.0
total_envstep_count: 166974
total_train_sample_count: 163962
total_episode_count: 10844
[2024-06-01 18:27:57][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 16.785340314136125
avg_sample_per_episode: 16.785340314136125
avg_envstep_per_sec: 71.16043160514901
avg_train_sample_per_sec: 71.16043160514901
avg_episode_per_sec: 4.23943931272098
reward_mean: 205.5916290283203
reward_std: 171.8394012451172
reward_max: 425.3999938964844
reward_min: -30.600000381469727
total_envstep_count: 170244
total_train_sample_count: 167168
total_episode_count: 11035
[2024-06-01 18:36:02][sample_serial_collector.py:406][INFO] collect end:
episode_count: 197
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 16.309644670050762
avg_sample_per_episode: 16.309644670050762
avg_envstep_per_sec: 72.11086398461114
avg_train_sample_per_sec: 72.11086398461114
avg_episode_per_sec: 4.42136327574491
reward_mean: 193.10049438476562
reward_std: 167.84768676757812
reward_max: 416.79998779296875
reward_min: -33.0
total_envstep_count: 173529
total_train_sample_count: 170381
total_episode_count: 11232
[2024-06-01 18:44:17][sample_serial_collector.py:406][INFO] collect end:
episode_count: 202
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 15.841584158415841
avg_sample_per_episode: 15.841584158415841
avg_envstep_per_sec: 70.25373645072273
avg_train_sample_per_sec: 70.25373645072273
avg_episode_per_sec: 4.434767113451873
reward_mean: 186.8237762451172
reward_std: 170.2172393798828
reward_max: 417.79998779296875
reward_min: -29.0
total_envstep_count: 176820
total_train_sample_count: 173581
total_episode_count: 11434
[2024-06-01 18:52:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 16.852631578947367
avg_sample_per_episode: 16.852631578947367
avg_envstep_per_sec: 72.58800712510711
avg_train_sample_per_sec: 72.58800712510711
avg_episode_per_sec: 4.307220909984494
reward_mean: 211.41896057128906
reward_std: 168.07725524902344
reward_max: 416.20001220703125
reward_min: -20.200000762939453
total_envstep_count: 180102
total_train_sample_count: 176783
total_episode_count: 11624
[2024-06-01 19:00:51][sample_serial_collector.py:406][INFO] collect end:
episode_count: 195
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 16.43076923076923
avg_sample_per_episode: 16.43076923076923
avg_envstep_per_sec: 69.3789354872628
avg_train_sample_per_sec: 69.3789354872628
avg_episode_per_sec: 4.222500755310938
reward_mean: 199.50462341308594
reward_std: 168.92030334472656
reward_max: 431.20001220703125
reward_min: -31.0
total_envstep_count: 183381
total_train_sample_count: 179987
total_episode_count: 11819
[2024-06-01 19:09:05][sample_serial_collector.py:406][INFO] collect end:
episode_count: 207
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 15.478260869565217
avg_sample_per_episode: 15.478260869565217
avg_envstep_per_sec: 71.21615795783543
avg_train_sample_per_sec: 71.21615795783543
avg_episode_per_sec: 4.6010439130062215
reward_mean: 174.6627960205078
reward_std: 166.0831298828125
reward_max: 410.3999938964844
reward_min: -30.200000762939453
total_envstep_count: 186666
total_train_sample_count: 183191
total_episode_count: 12026
[2024-06-01 19:17:25][sample_serial_collector.py:406][INFO] collect end:
episode_count: 198
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 16.161616161616163
avg_sample_per_episode: 16.161616161616163
avg_envstep_per_sec: 71.25636094984053
avg_train_sample_per_sec: 71.25636094984053
avg_episode_per_sec: 4.408987333771383
reward_mean: 195.84747314453125
reward_std: 170.04127502441406
reward_max: 419.0
reward_min: -38.0
total_envstep_count: 189938
total_train_sample_count: 186391
total_episode_count: 12224
[2024-06-01 19:25:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 184
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 17.456521739130434
avg_sample_per_episode: 17.456521739130434
avg_envstep_per_sec: 71.87234415710063
avg_train_sample_per_sec: 71.87234415710063
avg_episode_per_sec: 4.117220213233661
reward_mean: 228.32936096191406
reward_std: 173.7698516845703
reward_max: 420.0
reward_min: -26.0
total_envstep_count: 193220
total_train_sample_count: 189603
total_episode_count: 12408
[2024-06-01 19:33:58][sample_serial_collector.py:406][INFO] collect end:
episode_count: 185
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 17.318918918918918
avg_sample_per_episode: 17.318918918918918
avg_envstep_per_sec: 72.8222785044553
avg_train_sample_per_sec: 72.8222785044553
avg_episode_per_sec: 4.204781998540646
reward_mean: 218.3643341064453
reward_std: 165.47499084472656
reward_max: 424.20001220703125
reward_min: -25.399999618530273
total_envstep_count: 196493
total_train_sample_count: 192807
total_episode_count: 12593
[2024-06-01 19:42:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 16.952380952380953
avg_sample_per_episode: 16.952380952380953
avg_envstep_per_sec: 71.48304208508213
avg_train_sample_per_sec: 71.48304208508213
avg_episode_per_sec: 4.216696302771699
reward_mean: 212.3618927001953
reward_std: 167.98361206054688
reward_max: 425.6000061035156
reward_min: -24.799999237060547
total_envstep_count: 199763
total_train_sample_count: 196011
total_episode_count: 12782
[2024-06-01 19:51:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 193
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 16.580310880829014
avg_sample_per_episode: 16.580310880829014
avg_envstep_per_sec: 69.53766347744076
avg_train_sample_per_sec: 69.53766347744076
avg_episode_per_sec: 4.193990328483146
reward_mean: 201.50570678710938
reward_std: 168.7589569091797
reward_max: 441.3999938964844
reward_min: -20.200000762939453
total_envstep_count: 203029
total_train_sample_count: 199211
total_episode_count: 12975
[2024-06-01 20:00:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3243
train_sample_count: 3243
avg_envstep_per_episode: 16.890625
avg_sample_per_episode: 16.890625
avg_envstep_per_sec: 72.47918726397096
avg_train_sample_per_sec: 72.47918726397096
avg_episode_per_sec: 4.291089717755912
reward_mean: 209.4541778564453
reward_std: 170.44606018066406
reward_max: 433.79998779296875
reward_min: -33.0
total_envstep_count: 206333
total_train_sample_count: 202454
total_episode_count: 13167
[2024-06-01 20:09:09][sample_serial_collector.py:406][INFO] collect end:
episode_count: 179
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 17.899441340782122
avg_sample_per_episode: 17.899441340782122
avg_envstep_per_sec: 74.23190748316011
avg_train_sample_per_sec: 74.23190748316011
avg_episode_per_sec: 4.147163370625987
reward_mean: 230.83016967773438
reward_std: 164.53306579589844
reward_max: 424.79998779296875
reward_min: -21.0
total_envstep_count: 209614
total_train_sample_count: 205658
total_episode_count: 13346
[2024-06-01 20:17:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 17.021164021164022
avg_sample_per_episode: 17.021164021164022
avg_envstep_per_sec: 72.65326262940165
avg_train_sample_per_sec: 72.65326262940165
avg_episode_per_sec: 4.268407409685083
reward_mean: 215.11111450195312
reward_std: 170.91307067871094
reward_max: 426.6000061035156
reward_min: -24.600000381469727
total_envstep_count: 212895
total_train_sample_count: 208875
total_episode_count: 13535
[2024-06-01 20:26:46][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 16.952380952380953
avg_sample_per_episode: 16.952380952380953
avg_envstep_per_sec: 71.56385338916695
avg_train_sample_per_sec: 71.56385338916695
avg_episode_per_sec: 4.2214632617205226
reward_mean: 214.8962860107422
reward_std: 176.2954864501953
reward_max: 418.6000061035156
reward_min: -41.0
total_envstep_count: 216154
total_train_sample_count: 212079
total_episode_count: 13724
[2024-06-01 20:35:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 16.50515463917526
avg_sample_per_episode: 16.50515463917526
avg_envstep_per_sec: 72.39352276003602
avg_train_sample_per_sec: 72.39352276003602
avg_episode_per_sec: 4.386115994830415
reward_mean: 201.66392517089844
reward_std: 172.6473388671875
reward_max: 429.20001220703125
reward_min: -29.0
total_envstep_count: 219409
total_train_sample_count: 215281
total_episode_count: 13918
[2024-06-01 20:44:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 16.587628865979383
avg_sample_per_episode: 16.587628865979383
avg_envstep_per_sec: 70.88263798713635
avg_train_sample_per_sec: 70.88263798713635
avg_episode_per_sec: 4.273223048323323
reward_mean: 199.46597290039062
reward_std: 169.82717895507812
reward_max: 418.79998779296875
reward_min: -29.0
total_envstep_count: 222656
total_train_sample_count: 218499
total_episode_count: 14112
[2024-06-01 20:53:12][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 16.723958333333332
avg_sample_per_episode: 16.723958333333332
avg_envstep_per_sec: 72.23240339279147
avg_train_sample_per_sec: 72.23240339279147
avg_episode_per_sec: 4.319097306576133
reward_mean: 205.06146240234375
reward_std: 173.5859832763672
reward_max: 433.3999938964844
reward_min: -20.200000762939453
total_envstep_count: 225936
total_train_sample_count: 221710
total_episode_count: 14304
[2024-06-01 21:01:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3238
train_sample_count: 3238
avg_envstep_per_episode: 17.315508021390375
avg_sample_per_episode: 17.315508021390375
avg_envstep_per_sec: 74.48868289030901
avg_train_sample_per_sec: 74.48868289030901
avg_episode_per_sec: 4.301847961855399
reward_mean: 218.45880126953125
reward_std: 168.00845336914062
reward_max: 434.3999938964844
reward_min: -29.0
total_envstep_count: 229222
total_train_sample_count: 224948
total_episode_count: 14491
[2024-06-01 21:10:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 16.65463917525773
avg_sample_per_episode: 16.65463917525773
avg_envstep_per_sec: 73.41808995849999
avg_train_sample_per_sec: 73.41808995849999
avg_episode_per_sec: 4.408266620844629
reward_mean: 195.17420959472656
reward_std: 179.51710510253906
reward_max: 427.3999938964844
reward_min: -610.4000244140625
total_envstep_count: 232498
total_train_sample_count: 228179
total_episode_count: 14685
[2024-06-01 21:18:42][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 16.889473684210525
avg_sample_per_episode: 16.889473684210525
avg_envstep_per_sec: 71.6987213605891
avg_train_sample_per_sec: 71.6987213605891
avg_episode_per_sec: 4.245172034438121
reward_mean: 208.80422973632812
reward_std: 171.9469757080078
reward_max: 429.6000061035156
reward_min: -21.200000762939453
total_envstep_count: 235769
total_train_sample_count: 231388
total_episode_count: 14875
[2024-06-01 21:26:55][sample_serial_collector.py:406][INFO] collect end:
episode_count: 184
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 17.41304347826087
avg_sample_per_episode: 17.41304347826087
avg_envstep_per_sec: 73.71735741127192
avg_train_sample_per_sec: 73.71735741127192
avg_episode_per_sec: 4.233456230859561
reward_mean: 222.41087341308594
reward_std: 169.02120971679688
reward_max: 431.3999938964844
reward_min: -20.0
total_envstep_count: 239030
total_train_sample_count: 234592
total_episode_count: 15059
[2024-06-01 21:35:09][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 16.61340206185567
avg_sample_per_episode: 16.61340206185567
avg_envstep_per_sec: 69.64489667832338
avg_train_sample_per_sec: 69.64489667832338
avg_episode_per_sec: 4.192091205583225
reward_mean: 202.4690704345703
reward_std: 171.91781616210938
reward_max: 423.3999938964844
reward_min: -26.799999237060547
total_envstep_count: 242322
total_train_sample_count: 237815
total_episode_count: 15253
[2024-06-01 21:43:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 16.729166666666668
avg_sample_per_episode: 16.729166666666668
avg_envstep_per_sec: 73.29869123338837
avg_train_sample_per_sec: 73.29869123338837
avg_episode_per_sec: 4.381490883191335
reward_mean: 210.2510528564453
reward_std: 171.94590759277344
reward_max: 435.6000061035156
reward_min: -21.0
total_envstep_count: 245585
total_train_sample_count: 241027
total_episode_count: 15445
[2024-06-01 21:51:26][sample_serial_collector.py:406][INFO] collect end:
episode_count: 186
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 17.22043010752688
avg_sample_per_episode: 17.22043010752688
avg_envstep_per_sec: 74.74102830809223
avg_train_sample_per_sec: 74.74102830809223
avg_episode_per_sec: 4.34025328295509
reward_mean: 218.14515686035156
reward_std: 173.72328186035156
reward_max: 425.0
reward_min: -38.0
total_envstep_count: 248874
total_train_sample_count: 244230
total_episode_count: 15631
[2024-06-01 21:59:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 16.780104712041886
avg_sample_per_episode: 16.780104712041886
avg_envstep_per_sec: 70.3696699839495
avg_train_sample_per_sec: 70.3696699839495
avg_episode_per_sec: 4.193637119168286
reward_mean: 207.43246459960938
reward_std: 168.70233154296875
reward_max: 413.0
reward_min: -33.0
total_envstep_count: 252135
total_train_sample_count: 247435
total_episode_count: 15822
[2024-06-01 22:07:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 16.873684210526317
avg_sample_per_episode: 16.873684210526317
avg_envstep_per_sec: 73.62241686235186
avg_train_sample_per_sec: 73.62241686235186
avg_episode_per_sec: 4.363150094774439
reward_mean: 207.98313903808594
reward_std: 171.24517822265625
reward_max: 420.3999938964844
reward_min: -38.0
total_envstep_count: 255408
total_train_sample_count: 250641
total_episode_count: 16012
[2024-06-01 22:15:59][sample_serial_collector.py:406][INFO] collect end:
episode_count: 195
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 16.42051282051282
avg_sample_per_episode: 16.42051282051282
avg_envstep_per_sec: 70.75268811463103
avg_train_sample_per_sec: 70.75268811463103
avg_episode_per_sec: 4.30879893265242
reward_mean: 198.33128356933594
reward_std: 169.0426788330078
reward_max: 416.3999938964844
reward_min: -25.399999618530273
total_envstep_count: 258662
total_train_sample_count: 253843
total_episode_count: 16207
[2024-06-01 22:24:11][sample_serial_collector.py:406][INFO] collect end:
episode_count: 195
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 16.415384615384614
avg_sample_per_episode: 16.415384615384614
avg_envstep_per_sec: 72.29907953705934
avg_train_sample_per_sec: 72.29907953705934
avg_episode_per_sec: 4.404348800289464
reward_mean: 197.50152587890625
reward_std: 174.451904296875
reward_max: 426.20001220703125
reward_min: -29.0
total_envstep_count: 261940
total_train_sample_count: 257044
total_episode_count: 16402
[2024-06-01 22:40:12][sample_serial_collector.py:406][INFO] collect end:
episode_count: 193
envstep_count: 3222
train_sample_count: 3222
avg_envstep_per_episode: 16.694300518134714
avg_sample_per_episode: 16.694300518134714
avg_envstep_per_sec: 70.82335895190367
avg_train_sample_per_sec: 70.82335895190367
avg_episode_per_sec: 4.242367559812975
reward_mean: 206.139892578125
reward_std: 170.0456085205078
reward_max: 435.3999938964844
reward_min: -20.200000762939453
total_envstep_count: 265224
total_train_sample_count: 260266
total_episode_count: 16595
[2024-06-01 22:48:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 17.310160427807485
avg_sample_per_episode: 17.310160427807485
avg_envstep_per_sec: 74.77408998262555
avg_train_sample_per_sec: 74.77408998262555
avg_episode_per_sec: 4.319664759577071
reward_mean: 219.83102416992188
reward_std: 171.1999969482422
reward_max: 415.3999938964844
reward_min: -29.0
total_envstep_count: 268522
total_train_sample_count: 263503
total_episode_count: 16782
[2024-06-01 22:56:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 16.81151832460733
avg_sample_per_episode: 16.81151832460733
avg_envstep_per_sec: 72.09141169558175
avg_train_sample_per_sec: 72.09141169558175
avg_episode_per_sec: 4.288215395159177
reward_mean: 208.8523406982422
reward_std: 172.250244140625
reward_max: 414.3999938964844
reward_min: -29.0
total_envstep_count: 271768
total_train_sample_count: 266714
total_episode_count: 16973
[2024-06-01 23:04:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 17.149732620320854
avg_sample_per_episode: 17.149732620320854
avg_envstep_per_sec: 71.99007825935323
avg_train_sample_per_sec: 71.99007825935323
avg_episode_per_sec: 4.197737647177753
reward_mean: 216.0823516845703
reward_std: 171.13352966308594
reward_max: 431.3999938964844
reward_min: -33.0
total_envstep_count: 275069
total_train_sample_count: 269921
total_episode_count: 17160
[2024-06-01 23:12:51][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3229
train_sample_count: 3229
avg_envstep_per_episode: 17.175531914893618
avg_sample_per_episode: 17.175531914893618
avg_envstep_per_sec: 70.2270137330788
avg_train_sample_per_sec: 70.2270137330788
avg_episode_per_sec: 4.088782465722767
reward_mean: 220.44789123535156
reward_std: 170.3007354736328
reward_max: 410.20001220703125
reward_min: -29.0
total_envstep_count: 278376
total_train_sample_count: 273150
total_episode_count: 17348
[2024-06-01 23:21:19][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3234
train_sample_count: 3234
avg_envstep_per_episode: 16.93193717277487
avg_sample_per_episode: 16.93193717277487
avg_envstep_per_sec: 71.58735900306225
avg_train_sample_per_sec: 71.58735900306225
avg_episode_per_sec: 4.227948537286608
reward_mean: 211.8408203125
reward_std: 169.19406127929688
reward_max: 431.3999938964844
reward_min: -30.0
total_envstep_count: 281666
total_train_sample_count: 276384
total_episode_count: 17539
[2024-06-01 23:29:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 185
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 17.42162162162162
avg_sample_per_episode: 17.42162162162162
avg_envstep_per_sec: 72.05208314026304
avg_train_sample_per_sec: 72.05208314026304
avg_episode_per_sec: 4.13578510113207
reward_mean: 220.97189331054688
reward_std: 166.96759033203125
reward_max: 421.3999938964844
reward_min: -31.0
total_envstep_count: 284936
total_train_sample_count: 279607
total_episode_count: 17724
[2024-06-01 23:37:59][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 16.952380952380953
avg_sample_per_episode: 16.952380952380953
avg_envstep_per_sec: 70.2153248022089
avg_train_sample_per_sec: 70.2153248022089
avg_episode_per_sec: 4.141915227096592
reward_mean: 211.40211486816406
reward_std: 170.38746643066406
reward_max: 419.0
reward_min: -16.200000762939453
total_envstep_count: 288233
total_train_sample_count: 282811
total_episode_count: 17913
[2024-06-01 23:46:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 196
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 16.413265306122447
avg_sample_per_episode: 16.413265306122447
avg_envstep_per_sec: 72.04017324326604
avg_train_sample_per_sec: 72.04017324326604
avg_episode_per_sec: 4.389143287435544
reward_mean: 201.0234832763672
reward_std: 171.19989013671875
reward_max: 417.6000061035156
reward_min: -29.0
total_envstep_count: 291474
total_train_sample_count: 286028
total_episode_count: 18109
[2024-06-01 23:54:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 196
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 16.372448979591837
avg_sample_per_episode: 16.372448979591837
avg_envstep_per_sec: 71.08891698299342
avg_train_sample_per_sec: 71.08891698299342
avg_episode_per_sec: 4.341984334268218
reward_mean: 194.90509033203125
reward_std: 171.63290405273438
reward_max: 407.79998779296875
reward_min: -29.0
total_envstep_count: 294753
total_train_sample_count: 289237
total_episode_count: 18305
[2024-06-02 00:02:55][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 16.842931937172775
avg_sample_per_episode: 16.842931937172775
avg_envstep_per_sec: 68.95434336008924
avg_train_sample_per_sec: 68.95434336008924
avg_episode_per_sec: 4.093963189859199
reward_mean: 212.24398803710938
reward_std: 174.33702087402344
reward_max: 428.3999938964844
reward_min: -29.799999237060547
total_envstep_count: 297999
total_train_sample_count: 292454
total_episode_count: 18496
[2024-06-02 00:11:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 185
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 17.443243243243245
avg_sample_per_episode: 17.443243243243245
avg_envstep_per_sec: 73.4304290571853
avg_train_sample_per_sec: 73.4304290571853
avg_episode_per_sec: 4.20967752574505
reward_mean: 219.67782592773438
reward_std: 172.75904846191406
reward_max: 427.79998779296875
reward_min: -29.0
total_envstep_count: 301273
total_train_sample_count: 295681
total_episode_count: 18681
[2024-06-02 00:19:05][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 17.06382978723404
avg_sample_per_episode: 17.06382978723404
avg_envstep_per_sec: 71.7186764167451
avg_train_sample_per_sec: 71.7186764167451
avg_episode_per_sec: 4.2029648274152365
reward_mean: 215.07339477539062
reward_std: 172.34307861328125
reward_max: 431.6000061035156
reward_min: -17.0
total_envstep_count: 304556
total_train_sample_count: 298889
total_episode_count: 18869
[2024-06-02 00:27:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 193
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 16.66321243523316
avg_sample_per_episode: 16.66321243523316
avg_envstep_per_sec: 71.51713913844505
avg_train_sample_per_sec: 71.51713913844505
avg_episode_per_sec: 4.291917864962654
reward_mean: 204.85597229003906
reward_std: 170.6957244873047
reward_max: 434.3999938964844
reward_min: -33.0
total_envstep_count: 307825
total_train_sample_count: 302105
total_episode_count: 19062
[2024-06-02 00:35:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 182
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 17.64835164835165
avg_sample_per_episode: 17.64835164835165
avg_envstep_per_sec: 72.14902517318323
avg_train_sample_per_sec: 72.14902517318323
avg_episode_per_sec: 4.088145261992325
reward_mean: 230.83628845214844
reward_std: 171.42137145996094
reward_max: 423.6000061035156
reward_min: -29.0
total_envstep_count: 311105
total_train_sample_count: 305317
total_episode_count: 19244
[2024-06-02 00:43:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 200
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 16.035
avg_sample_per_episode: 16.035
avg_envstep_per_sec: 73.18613398686277
avg_train_sample_per_sec: 73.18613398686277
avg_episode_per_sec: 4.564149297590443
reward_mean: 191.31900024414062
reward_std: 171.9061737060547
reward_max: 439.6000061035156
reward_min: -31.0
total_envstep_count: 314376
total_train_sample_count: 308524
total_episode_count: 19444
[2024-06-02 00:51:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 17.176470588235293
avg_sample_per_episode: 17.176470588235293
avg_envstep_per_sec: 74.04071352811948
avg_train_sample_per_sec: 74.04071352811948
avg_episode_per_sec: 4.310589486226134
reward_mean: 213.40213012695312
reward_std: 167.94757080078125
reward_max: 415.79998779296875
reward_min: -27.799999237060547
total_envstep_count: 317654
total_train_sample_count: 311736
total_episode_count: 19631
[2024-06-02 01:00:05][sample_serial_collector.py:406][INFO] collect end:
episode_count: 204
envstep_count: 3232
train_sample_count: 3232
avg_envstep_per_episode: 15.843137254901961
avg_sample_per_episode: 15.843137254901961
avg_envstep_per_sec: 69.6362129494088
avg_train_sample_per_sec: 69.6362129494088
avg_episode_per_sec: 4.39535502527209
reward_mean: 186.4068603515625
reward_std: 172.14309692382812
reward_max: 422.6000061035156
reward_min: -22.200000762939453
total_envstep_count: 320929
total_train_sample_count: 314968
total_episode_count: 19835
[2024-06-02 01:08:18][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 16.994708994708994
avg_sample_per_episode: 16.994708994708994
avg_envstep_per_sec: 71.68410567276723
avg_train_sample_per_sec: 71.68410567276723
avg_episode_per_sec: 4.218024897930575
reward_mean: 214.63702392578125
reward_std: 174.3341827392578
reward_max: 419.3999938964844
reward_min: -31.0
total_envstep_count: 324197
total_train_sample_count: 318180
total_episode_count: 20024
[2024-06-02 01:16:27][sample_serial_collector.py:406][INFO] collect end:
episode_count: 186
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 17.295698924731184
avg_sample_per_episode: 17.295698924731184
avg_envstep_per_sec: 72.89059017783526
avg_train_sample_per_sec: 72.89059017783526
avg_episode_per_sec: 4.21437667798488
reward_mean: 222.06666564941406
reward_std: 172.7573699951172
reward_max: 431.3999938964844
reward_min: -26.600000381469727
total_envstep_count: 327522
total_train_sample_count: 321397
total_episode_count: 20210
[2024-06-02 01:24:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 201
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 15.930348258706468
avg_sample_per_episode: 15.930348258706468
avg_envstep_per_sec: 72.13795086857571
avg_train_sample_per_sec: 72.13795086857571
avg_episode_per_sec: 4.528334829663872
reward_mean: 189.14625549316406
reward_std: 168.41807556152344
reward_max: 425.6000061035156
reward_min: -21.0
total_envstep_count: 330813
total_train_sample_count: 324599
total_episode_count: 20411
[2024-06-02 01:33:03][sample_serial_collector.py:406][INFO] collect end:
episode_count: 182
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 17.60989010989011
avg_sample_per_episode: 17.60989010989011
avg_envstep_per_sec: 71.99345234865598
avg_train_sample_per_sec: 71.99345234865598
avg_episode_per_sec: 4.088239727755192
reward_mean: 229.92198181152344
reward_std: 163.86422729492188
reward_max: 419.3999938964844
reward_min: -16.200000762939453
total_envstep_count: 334073
total_train_sample_count: 327804
total_episode_count: 20593
[2024-06-02 01:41:18][sample_serial_collector.py:406][INFO] collect end:
episode_count: 181
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 17.834254143646408
avg_sample_per_episode: 17.834254143646408
avg_envstep_per_sec: 73.13307448067614
avg_train_sample_per_sec: 73.13307448067614
avg_episode_per_sec: 4.100708327448074
reward_mean: 232.4994354248047
reward_std: 169.29617309570312
reward_max: 424.20001220703125
reward_min: -38.0
total_envstep_count: 337354
total_train_sample_count: 331032
total_episode_count: 20774
[2024-06-02 01:49:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 185
envstep_count: 3239
train_sample_count: 3239
avg_envstep_per_episode: 17.508108108108107
avg_sample_per_episode: 17.508108108108107
avg_envstep_per_sec: 72.63086927306813
avg_train_sample_per_sec: 72.63086927306813
avg_episode_per_sec: 4.148413342240692
reward_mean: 228.1621551513672
reward_std: 173.60427856445312
reward_max: 421.3999938964844
reward_min: -21.0
total_envstep_count: 340648
total_train_sample_count: 334271
total_episode_count: 20959
[2024-06-02 01:58:02][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 17.03723404255319
avg_sample_per_episode: 17.03723404255319
avg_envstep_per_sec: 69.14322874659692
avg_train_sample_per_sec: 69.14322874659692
avg_episode_per_sec: 4.0583599763847085
reward_mean: 216.9234161376953
reward_std: 173.44894409179688
reward_max: 435.6000061035156
reward_min: -38.0
total_envstep_count: 343884
total_train_sample_count: 337474
total_episode_count: 21147
[2024-06-02 02:06:18][sample_serial_collector.py:406][INFO] collect end:
episode_count: 182
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 17.60989010989011
avg_sample_per_episode: 17.60989010989011
avg_envstep_per_sec: 71.25876656607461
avg_train_sample_per_sec: 71.25876656607461
avg_episode_per_sec: 4.04651966147444
reward_mean: 225.22528076171875
reward_std: 170.7072296142578
reward_max: 425.0
reward_min: -33.0
total_envstep_count: 347179
total_train_sample_count: 340679
total_episode_count: 21329
[2024-06-02 02:14:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 16.941798941798943
avg_sample_per_episode: 16.941798941798943
avg_envstep_per_sec: 71.94109941294435
avg_train_sample_per_sec: 71.94109941294435
avg_episode_per_sec: 4.246367204574168
reward_mean: 215.1195831298828
reward_std: 171.86441040039062
reward_max: 432.79998779296875
reward_min: -38.0
total_envstep_count: 350428
total_train_sample_count: 343881
total_episode_count: 21518
[2024-06-02 02:22:58][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 17.245989304812834
avg_sample_per_episode: 17.245989304812834
avg_envstep_per_sec: 73.96129880680644
avg_train_sample_per_sec: 73.96129880680644
avg_episode_per_sec: 4.288608643991568
reward_mean: 217.3015899658203
reward_std: 169.05470275878906
reward_max: 413.3999938964844
reward_min: -17.0
total_envstep_count: 353728
total_train_sample_count: 347106
total_episode_count: 21705
[2024-06-02 02:31:20][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 16.515463917525775
avg_sample_per_episode: 16.515463917525775
avg_envstep_per_sec: 73.2593270846288
avg_train_sample_per_sec: 73.2593270846288
avg_episode_per_sec: 4.435801952065538
reward_mean: 205.0309295654297
reward_std: 174.12142944335938
reward_max: 420.0
reward_min: -29.0
total_envstep_count: 356986
total_train_sample_count: 350310
total_episode_count: 21899
[2024-06-02 02:39:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 17.197860962566846
avg_sample_per_episode: 17.197860962566846
avg_envstep_per_sec: 72.37679886280556
avg_train_sample_per_sec: 72.37679886280556
avg_episode_per_sec: 4.208476799547462
reward_mean: 216.480224609375
reward_std: 172.34637451171875
reward_max: 416.20001220703125
reward_min: -33.79999923706055
total_envstep_count: 360256
total_train_sample_count: 353526
total_episode_count: 22086
[2024-06-02 02:48:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 199
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 16.150753768844222
avg_sample_per_episode: 16.150753768844222
avg_envstep_per_sec: 71.29779875650114
avg_train_sample_per_sec: 71.29779875650114
avg_episode_per_sec: 4.414518342421819
reward_mean: 192.47740173339844
reward_std: 172.28598022460938
reward_max: 417.3999938964844
reward_min: -29.0
total_envstep_count: 363541
total_train_sample_count: 356740
total_episode_count: 22285
[2024-06-02 02:56:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 16.847368421052632
avg_sample_per_episode: 16.847368421052632
avg_envstep_per_sec: 70.76874019975372
avg_train_sample_per_sec: 70.76874019975372
avg_episode_per_sec: 4.200581267714217
reward_mean: 211.0494842529297
reward_std: 172.69664001464844
reward_max: 435.6000061035156
reward_min: -21.0
total_envstep_count: 366782
total_train_sample_count: 359941
total_episode_count: 22475
[2024-06-02 03:04:48][sample_serial_collector.py:406][INFO] collect end:
episode_count: 197
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 16.314720812182742
avg_sample_per_episode: 16.314720812182742
avg_envstep_per_sec: 69.72574379751163
avg_train_sample_per_sec: 69.72574379751163
avg_episode_per_sec: 4.273793257034782
reward_mean: 194.54925537109375
reward_std: 172.9031219482422
reward_max: 429.0
reward_min: -29.0
total_envstep_count: 370086
total_train_sample_count: 363155
total_episode_count: 22672
[2024-06-02 03:13:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 179
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 17.905027932960895
avg_sample_per_episode: 17.905027932960895
avg_envstep_per_sec: 72.99804476499718
avg_train_sample_per_sec: 72.99804476499718
avg_episode_per_sec: 4.0769578823508565
reward_mean: 242.80783081054688
reward_std: 170.4743194580078
reward_max: 431.3999938964844
reward_min: -33.0
total_envstep_count: 373347
total_train_sample_count: 366360
total_episode_count: 22851
[2024-06-02 03:21:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 177
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 18.096045197740114
avg_sample_per_episode: 18.096045197740114
avg_envstep_per_sec: 72.72467851081586
avg_train_sample_per_sec: 72.72467851081586
avg_episode_per_sec: 4.018816139998254
reward_mean: 241.3389892578125
reward_std: 168.79885864257812
reward_max: 421.3999938964844
reward_min: -20.200000762939453
total_envstep_count: 376612
total_train_sample_count: 369563
total_episode_count: 23028
[2024-06-02 03:29:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 198
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 16.18686868686869
avg_sample_per_episode: 16.18686868686869
avg_envstep_per_sec: 72.50283234359405
avg_train_sample_per_sec: 72.50283234359405
avg_episode_per_sec: 4.479114135423283
reward_mean: 195.22727966308594
reward_std: 174.84571838378906
reward_max: 421.3999938964844
reward_min: -21.0
total_envstep_count: 379881
total_train_sample_count: 372768
total_episode_count: 23226
[2024-06-02 03:38:06][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 16.848958333333332
avg_sample_per_episode: 16.848958333333332
avg_envstep_per_sec: 70.42265711592901
avg_train_sample_per_sec: 70.42265711592901
avg_episode_per_sec: 4.1796445645311815
reward_mean: 208.0364532470703
reward_std: 168.62991333007812
reward_max: 438.6000061035156
reward_min: -29.0
total_envstep_count: 383158
total_train_sample_count: 376003
total_episode_count: 23418
[2024-06-02 03:46:17][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 16.692708333333332
avg_sample_per_episode: 16.692708333333332
avg_envstep_per_sec: 71.17949795462408
avg_train_sample_per_sec: 71.17949795462408
avg_episode_per_sec: 4.264107209762192
reward_mean: 203.3937530517578
reward_std: 170.98846435546875
reward_max: 414.20001220703125
reward_min: -21.0
total_envstep_count: 386437
total_train_sample_count: 379208
total_episode_count: 23610
[2024-06-02 03:54:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 190
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 16.847368421052632
avg_sample_per_episode: 16.847368421052632
avg_envstep_per_sec: 72.57694266282105
avg_train_sample_per_sec: 72.57694266282105
avg_episode_per_sec: 4.307909748808497
reward_mean: 211.09580993652344
reward_std: 171.6082305908203
reward_max: 415.6000061035156
reward_min: -29.0
total_envstep_count: 389700
total_train_sample_count: 382409
total_episode_count: 23800
[2024-06-02 04:02:33][sample_serial_collector.py:406][INFO] collect end:
episode_count: 196
envstep_count: 3266
train_sample_count: 3266
avg_envstep_per_episode: 16.663265306122447
avg_sample_per_episode: 16.663265306122447
avg_envstep_per_sec: 71.88229632043031
avg_train_sample_per_sec: 71.88229632043031
avg_episode_per_sec: 4.313818150276895
reward_mean: 203.15103149414062
reward_std: 169.94244384765625
reward_max: 431.6000061035156
reward_min: -20.200000762939453
total_envstep_count: 392987
total_train_sample_count: 385675
total_episode_count: 23996
[2024-06-02 04:10:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 182
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 17.692307692307693
avg_sample_per_episode: 17.692307692307693
avg_envstep_per_sec: 74.65732610239661
avg_train_sample_per_sec: 74.65732610239661
avg_episode_per_sec: 4.21976191013546
reward_mean: 224.69561767578125
reward_std: 170.7980194091797
reward_max: 422.0
reward_min: -23.0
total_envstep_count: 396285
total_train_sample_count: 388895
total_episode_count: 24178
[2024-06-02 04:18:51][sample_serial_collector.py:406][INFO] collect end:
episode_count: 188
envstep_count: 3243
train_sample_count: 3243
avg_envstep_per_episode: 17.25
avg_sample_per_episode: 17.25
avg_envstep_per_sec: 72.23614115086767
avg_train_sample_per_sec: 72.23614115086767
avg_episode_per_sec: 4.187602385557546
reward_mean: 225.7733917236328
reward_std: 174.84446716308594
reward_max: 425.0
reward_min: -33.0
total_envstep_count: 399565
total_train_sample_count: 392138
total_episode_count: 24366
[2024-06-02 04:26:59][sample_serial_collector.py:406][INFO] collect end:
episode_count: 187
envstep_count: 3265
train_sample_count: 3265
avg_envstep_per_episode: 17.459893048128343
avg_sample_per_episode: 17.459893048128343
avg_envstep_per_sec: 71.53134134271677
avg_train_sample_per_sec: 71.53134134271677
avg_episode_per_sec: 4.0968945883883725
reward_mean: 215.59893798828125
reward_std: 167.49461364746094
reward_max: 409.20001220703125
reward_min: -33.0
total_envstep_count: 402883
total_train_sample_count: 395403
total_episode_count: 24553
[2024-06-02 04:35:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 17.03174603174603
avg_sample_per_episode: 17.03174603174603
avg_envstep_per_sec: 70.960235049637
avg_train_sample_per_sec: 70.960235049637
avg_episode_per_sec: 4.166351172532275
reward_mean: 208.64657592773438
reward_std: 165.72743225097656
reward_max: 420.0
reward_min: -29.0
total_envstep_count: 406177
total_train_sample_count: 398622
total_episode_count: 24742
[2024-06-02 04:43:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 17.052910052910054
avg_sample_per_episode: 17.052910052910054
avg_envstep_per_sec: 73.59835963728045
avg_train_sample_per_sec: 73.59835963728045
avg_episode_per_sec: 4.315882709105183
reward_mean: 215.1629638671875
reward_std: 170.208251953125
reward_max: 428.6000061035156
reward_min: -38.0
total_envstep_count: 409451
total_train_sample_count: 401845
total_episode_count: 24931
[2024-06-02 04:51:56][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 16.916230366492147
avg_sample_per_episode: 16.916230366492147
avg_envstep_per_sec: 72.97662899372777
avg_train_sample_per_sec: 72.97662899372777
avg_episode_per_sec: 4.31400066165336
reward_mean: 208.95497131347656
reward_std: 170.5333709716797
reward_max: 421.3999938964844
reward_min: -33.0
total_envstep_count: 412734
total_train_sample_count: 405076
total_episode_count: 25122
[2024-06-02 05:00:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 181
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 17.734806629834253
avg_sample_per_episode: 17.734806629834253
avg_envstep_per_sec: 72.04167882536119
avg_train_sample_per_sec: 72.04167882536119
avg_episode_per_sec: 4.0621631985639794
reward_mean: 227.5569305419922
reward_std: 167.6753692626953
reward_max: 427.3999938964844
reward_min: -21.0
total_envstep_count: 415995
total_train_sample_count: 408286
total_episode_count: 25303
[2024-06-02 05:08:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 194
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 16.5
avg_sample_per_episode: 16.5
avg_envstep_per_sec: 71.77838338820936
avg_train_sample_per_sec: 71.77838338820936
avg_episode_per_sec: 4.350205053830871
reward_mean: 197.801025390625
reward_std: 169.88571166992188
reward_max: 429.6000061035156
reward_min: -38.0
total_envstep_count: 419245
total_train_sample_count: 411487
total_episode_count: 25497
[2024-06-02 05:17:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 16.708333333333332
avg_sample_per_episode: 16.708333333333332
avg_envstep_per_sec: 72.64988791686325
avg_train_sample_per_sec: 72.64988791686325
avg_episode_per_sec: 4.348122967592813
reward_mean: 205.62083435058594
reward_std: 173.64517211914062
reward_max: 433.79998779296875
reward_min: -38.0
total_envstep_count: 422531
total_train_sample_count: 414695
total_episode_count: 25689
[2024-06-02 05:25:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 189
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 17.058201058201057
avg_sample_per_episode: 17.058201058201057
avg_envstep_per_sec: 75.1101248419422
avg_train_sample_per_sec: 75.1101248419422
avg_episode_per_sec: 4.403167988562989
reward_mean: 218.82752990722656
reward_std: 173.76820373535156
reward_max: 431.6000061035156
reward_min: -30.600000381469727
total_envstep_count: 425796
total_train_sample_count: 417919
total_episode_count: 25878
