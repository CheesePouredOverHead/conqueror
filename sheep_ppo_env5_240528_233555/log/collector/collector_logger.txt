[2024-05-28 23:43:44][sample_serial_collector.py:406][INFO] collect end:
episode_count: 672
envstep_count: 6451
train_sample_count: 6451
avg_envstep_per_episode: 9.599702380952381
avg_sample_per_episode: 9.599702380952381
avg_envstep_per_sec: 203.48659906317025
avg_train_sample_per_sec: 203.48659906317025
avg_episode_per_sec: 21.19717789031939
reward_mean: 37.22321319580078
reward_std: 61.61708068847656
reward_max: 328.0
reward_min: -50.0
total_envstep_count: 6484
total_train_sample_count: 6451
total_episode_count: 672
[2024-05-28 23:50:57][sample_serial_collector.py:406][INFO] collect end:
episode_count: 284
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 11.295774647887324
avg_sample_per_episode: 11.295774647887324
avg_envstep_per_sec: 203.81100211857932
avg_train_sample_per_sec: 203.81100211857932
avg_episode_per_sec: 18.043118641420364
reward_mean: 65.4366226196289
reward_std: 73.8166275024414
reward_max: 412.0
reward_min: -50.0
total_envstep_count: 9728
total_train_sample_count: 9659
total_episode_count: 956
[2024-05-28 23:58:11][sample_serial_collector.py:406][INFO] collect end:
episode_count: 258
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 12.44186046511628
avg_sample_per_episode: 12.44186046511628
avg_envstep_per_sec: 206.37036731728165
avg_train_sample_per_sec: 206.37036731728165
avg_episode_per_sec: 16.586777186248806
reward_mean: 83.30232238769531
reward_std: 87.30687713623047
reward_max: 418.0
reward_min: -50.0
total_envstep_count: 12992
total_train_sample_count: 12869
total_episode_count: 1214
[2024-05-29 00:05:26][sample_serial_collector.py:406][INFO] collect end:
episode_count: 230
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 14.004347826086956
avg_sample_per_episode: 14.004347826086956
avg_envstep_per_sec: 207.87764375030542
avg_train_sample_per_sec: 207.87764375030542
avg_episode_per_sec: 14.843793251341275
reward_mean: 108.94782257080078
reward_std: 99.34248352050781
reward_max: 484.0
reward_min: -50.0
total_envstep_count: 16260
total_train_sample_count: 16090
total_episode_count: 1444
[2024-05-29 00:12:42][sample_serial_collector.py:406][INFO] collect end:
episode_count: 226
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 14.238938053097344
avg_sample_per_episode: 14.238938053097344
avg_envstep_per_sec: 207.38630825190444
avg_train_sample_per_sec: 207.38630825190444
avg_episode_per_sec: 14.564731406131264
reward_mean: 111.41593170166016
reward_std: 105.99004364013672
reward_max: 496.0
reward_min: -38.0
total_envstep_count: 19551
total_train_sample_count: 19308
total_episode_count: 1670
[2024-05-29 00:19:57][sample_serial_collector.py:406][INFO] collect end:
episode_count: 195
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 16.456410256410255
avg_sample_per_episode: 16.456410256410255
avg_envstep_per_sec: 206.37838703995527
avg_train_sample_per_sec: 206.37838703995527
avg_episode_per_sec: 12.540911646242218
reward_mean: 147.53846740722656
reward_std: 115.82255554199219
reward_max: 646.0
reward_min: -50.0
total_envstep_count: 22802
total_train_sample_count: 22517
total_episode_count: 1865
[2024-05-29 00:27:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 191
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 16.769633507853403
avg_sample_per_episode: 16.769633507853403
avg_envstep_per_sec: 207.94466370429532
avg_train_sample_per_sec: 207.94466370429532
avg_episode_per_sec: 12.400072047305779
reward_mean: 148.15707397460938
reward_std: 129.96446228027344
reward_max: 724.0
reward_min: -38.0
total_envstep_count: 26087
total_train_sample_count: 25720
total_episode_count: 2056
[2024-05-29 00:34:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 192
envstep_count: 3227
train_sample_count: 3227
avg_envstep_per_episode: 16.807291666666668
avg_sample_per_episode: 16.807291666666668
avg_envstep_per_sec: 206.4852640943677
avg_train_sample_per_sec: 206.4852640943677
avg_episode_per_sec: 12.285457299695878
reward_mean: 152.0625
reward_std: 119.30892944335938
reward_max: 586.0
reward_min: -38.0
total_envstep_count: 29382
total_train_sample_count: 28947
total_episode_count: 2248
[2024-05-29 00:41:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 179
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 17.899441340782122
avg_sample_per_episode: 17.899441340782122
avg_envstep_per_sec: 211.10330067998194
avg_train_sample_per_sec: 211.10330067998194
avg_episode_per_sec: 11.79384857107265
reward_mean: 167.00558471679688
reward_std: 115.0151596069336
reward_max: 526.0
reward_min: -50.0
total_envstep_count: 32630
total_train_sample_count: 32151
total_episode_count: 2427
[2024-05-29 00:49:03][sample_serial_collector.py:406][INFO] collect end:
episode_count: 181
envstep_count: 3212
train_sample_count: 3212
avg_envstep_per_episode: 17.74585635359116
avg_sample_per_episode: 17.74585635359116
avg_envstep_per_sec: 210.9353775811829
avg_train_sample_per_sec: 210.9353775811829
avg_episode_per_sec: 11.886458076648227
reward_mean: 163.91160583496094
reward_std: 113.80449676513672
reward_max: 496.0
reward_min: -50.0
total_envstep_count: 35901
total_train_sample_count: 35363
total_episode_count: 2608
[2024-05-29 00:56:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 176
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 18.267045454545453
avg_sample_per_episode: 18.267045454545453
avg_envstep_per_sec: 207.79222320284632
avg_train_sample_per_sec: 207.79222320284632
avg_episode_per_sec: 11.375250788087387
reward_mean: 172.53408813476562
reward_std: 142.7722625732422
reward_max: 1034.0
reward_min: -50.0
total_envstep_count: 39187
total_train_sample_count: 38578
total_episode_count: 2784
[2024-05-29 01:03:37][sample_serial_collector.py:406][INFO] collect end:
episode_count: 166
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 19.33132530120482
avg_sample_per_episode: 19.33132530120482
avg_envstep_per_sec: 209.69980281088263
avg_train_sample_per_sec: 209.69980281088263
avg_episode_per_sec: 10.847668203990812
reward_mean: 194.44578552246094
reward_std: 164.17626953125
reward_max: 1016.0
reward_min: -50.0
total_envstep_count: 42466
total_train_sample_count: 41787
total_episode_count: 2950
[2024-05-29 01:10:54][sample_serial_collector.py:406][INFO] collect end:
episode_count: 179
envstep_count: 3244
train_sample_count: 3244
avg_envstep_per_episode: 18.122905027932962
avg_sample_per_episode: 18.122905027932962
avg_envstep_per_sec: 205.9335873295728
avg_train_sample_per_sec: 205.9335873295728
avg_episode_per_sec: 11.363166501847573
reward_mean: 171.094970703125
reward_std: 131.85740661621094
reward_max: 652.0
reward_min: -50.0
total_envstep_count: 45803
total_train_sample_count: 45031
total_episode_count: 3129
[2024-05-29 01:18:12][sample_serial_collector.py:406][INFO] collect end:
episode_count: 159
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 20.27672955974843
avg_sample_per_episode: 20.27672955974843
avg_envstep_per_sec: 212.72947231044822
avg_train_sample_per_sec: 212.72947231044822
avg_episode_per_sec: 10.491310824243568
reward_mean: 213.79873657226562
reward_std: 189.11009216308594
reward_max: 1028.0
reward_min: -50.0
total_envstep_count: 49115
total_train_sample_count: 48255
total_episode_count: 3288
[2024-05-29 01:25:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 162
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 19.77777777777778
avg_sample_per_episode: 19.77777777777778
avg_envstep_per_sec: 209.094263722707
avg_train_sample_per_sec: 209.094263722707
avg_episode_per_sec: 10.572181873620018
reward_mean: 201.86419677734375
reward_std: 159.90771484375
reward_max: 980.0
reward_min: -50.0
total_envstep_count: 52367
total_train_sample_count: 51459
total_episode_count: 3450
[2024-05-29 01:32:47][sample_serial_collector.py:406][INFO] collect end:
episode_count: 151
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 21.397350993377483
avg_sample_per_episode: 21.397350993377483
avg_envstep_per_sec: 209.69206121997786
avg_train_sample_per_sec: 209.69206121997786
avg_episode_per_sec: 9.799907534576496
reward_mean: 224.5960235595703
reward_std: 141.8863983154297
reward_max: 992.0
reward_min: -14.0
total_envstep_count: 55642
total_train_sample_count: 54690
total_episode_count: 3601
[2024-05-29 01:40:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 152
envstep_count: 3228
train_sample_count: 3228
avg_envstep_per_episode: 21.236842105263158
avg_sample_per_episode: 21.236842105263158
avg_envstep_per_sec: 208.62820783169465
avg_train_sample_per_sec: 208.62820783169465
avg_episode_per_sec: 9.823880914007926
reward_mean: 220.86842346191406
reward_std: 174.86050415039062
reward_max: 962.0
reward_min: -38.0
total_envstep_count: 58912
total_train_sample_count: 57918
total_episode_count: 3753
[2024-05-29 01:47:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 163
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 19.662576687116566
avg_sample_per_episode: 19.662576687116566
avg_envstep_per_sec: 209.24076388027817
avg_train_sample_per_sec: 209.24076388027817
avg_episode_per_sec: 10.64157395085346
reward_mean: 194.12269592285156
reward_std: 124.96864318847656
reward_max: 622.0
reward_min: -38.0
total_envstep_count: 62202
total_train_sample_count: 61123
total_episode_count: 3916
[2024-05-29 01:54:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 148
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 21.75
avg_sample_per_episode: 21.75
avg_envstep_per_sec: 211.51007673582362
avg_train_sample_per_sec: 211.51007673582362
avg_episode_per_sec: 9.724601229233269
reward_mean: 232.1216278076172
reward_std: 140.2457733154297
reward_max: 628.0
reward_min: -50.0
total_envstep_count: 65496
total_train_sample_count: 64342
total_episode_count: 4064
[2024-05-29 02:01:59][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 21.496644295302012
avg_sample_per_episode: 21.496644295302012
avg_envstep_per_sec: 209.26639354043493
avg_train_sample_per_sec: 209.26639354043493
avg_episode_per_sec: 9.734840036692102
reward_mean: 227.08724975585938
reward_std: 134.59568786621094
reward_max: 520.0
reward_min: -38.0
total_envstep_count: 68735
total_train_sample_count: 67545
total_episode_count: 4213
[2024-05-29 02:09:14][sample_serial_collector.py:406][INFO] collect end:
episode_count: 162
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 19.84567901234568
avg_sample_per_episode: 19.84567901234568
avg_envstep_per_sec: 206.5221418252962
avg_train_sample_per_sec: 206.5221418252962
avg_episode_per_sec: 10.406403413902948
reward_mean: 193.09877014160156
reward_std: 147.9361114501953
reward_max: 980.0
reward_min: -50.0
total_envstep_count: 72050
total_train_sample_count: 70760
total_episode_count: 4375
[2024-05-29 02:16:33][sample_serial_collector.py:406][INFO] collect end:
episode_count: 152
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 21.151315789473685
avg_sample_per_episode: 21.151315789473685
avg_envstep_per_sec: 207.92181275298213
avg_train_sample_per_sec: 207.92181275298213
avg_episode_per_sec: 9.830207010405376
reward_mean: 221.0
reward_std: 159.1409454345703
reward_max: 962.0
reward_min: -50.0
total_envstep_count: 75331
total_train_sample_count: 73975
total_episode_count: 4527
[2024-05-29 02:23:46][sample_serial_collector.py:406][INFO] collect end:
episode_count: 152
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 21.157894736842106
avg_sample_per_episode: 21.157894736842106
avg_envstep_per_sec: 211.96017003977747
avg_train_sample_per_sec: 211.96017003977747
avg_episode_per_sec: 10.018017986954657
reward_mean: 220.25
reward_std: 158.06900024414062
reward_max: 938.0
reward_min: -50.0
total_envstep_count: 78628
total_train_sample_count: 77191
total_episode_count: 4679
[2024-05-29 02:31:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 22.426573426573427
avg_sample_per_episode: 22.426573426573427
avg_envstep_per_sec: 207.62837665852842
avg_train_sample_per_sec: 207.62837665852842
avg_episode_per_sec: 9.258140898712057
reward_mean: 246.78321838378906
reward_std: 153.3697967529297
reward_max: 974.0
reward_min: -38.0
total_envstep_count: 81911
total_train_sample_count: 80398
total_episode_count: 4822
[2024-05-29 02:38:19][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 21.563758389261746
avg_sample_per_episode: 21.563758389261746
avg_envstep_per_sec: 212.85816074039627
avg_train_sample_per_sec: 212.85816074039627
avg_episode_per_sec: 9.871106738350154
reward_mean: 227.95973205566406
reward_std: 150.696533203125
reward_max: 920.0
reward_min: -38.0
total_envstep_count: 85208
total_train_sample_count: 83611
total_episode_count: 4971
[2024-05-29 02:45:37][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 21.816326530612244
avg_sample_per_episode: 21.816326530612244
avg_envstep_per_sec: 212.1652327583117
avg_train_sample_per_sec: 212.1652327583117
avg_episode_per_sec: 9.725066796218217
reward_mean: 236.16326904296875
reward_std: 164.8954315185547
reward_max: 914.0
reward_min: -50.0
total_envstep_count: 88511
total_train_sample_count: 86818
total_episode_count: 5118
[2024-05-29 02:52:50][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 21.453333333333333
avg_sample_per_episode: 21.453333333333333
avg_envstep_per_sec: 209.53335498121277
avg_train_sample_per_sec: 209.53335498121277
avg_episode_per_sec: 9.766936994152243
reward_mean: 230.586669921875
reward_std: 182.00184631347656
reward_max: 974.0
reward_min: -50.0
total_envstep_count: 91781
total_train_sample_count: 90036
total_episode_count: 5268
[2024-05-29 03:00:09][sample_serial_collector.py:406][INFO] collect end:
episode_count: 155
envstep_count: 3224
train_sample_count: 3224
avg_envstep_per_episode: 20.8
avg_sample_per_episode: 20.8
avg_envstep_per_sec: 208.95474866368085
avg_train_sample_per_sec: 208.95474866368085
avg_episode_per_sec: 10.04590137806158
reward_mean: 212.9290313720703
reward_std: 162.56336975097656
reward_max: 1022.0
reward_min: -50.0
total_envstep_count: 95087
total_train_sample_count: 93260
total_episode_count: 5423
[2024-05-29 03:07:26][sample_serial_collector.py:406][INFO] collect end:
episode_count: 151
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 21.397350993377483
avg_sample_per_episode: 21.397350993377483
avg_envstep_per_sec: 209.67232631081083
avg_train_sample_per_sec: 209.67232631081083
avg_episode_per_sec: 9.798985228391345
reward_mean: 224.6490020751953
reward_std: 173.33465576171875
reward_max: 974.0
reward_min: -50.0
total_envstep_count: 98440
total_train_sample_count: 96491
total_episode_count: 5574
[2024-05-29 03:14:42][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 21.386666666666667
avg_sample_per_episode: 21.386666666666667
avg_envstep_per_sec: 213.05467314266815
avg_train_sample_per_sec: 213.05467314266815
avg_episode_per_sec: 9.962032721758174
reward_mean: 228.75999450683594
reward_std: 179.1302947998047
reward_max: 956.0
reward_min: -50.0
total_envstep_count: 101739
total_train_sample_count: 99699
total_episode_count: 5724
[2024-05-29 03:22:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 22.454545454545453
avg_sample_per_episode: 22.454545454545453
avg_envstep_per_sec: 212.7069323605033
avg_train_sample_per_sec: 212.7069323605033
avg_episode_per_sec: 9.472778364232939
reward_mean: 249.28671264648438
reward_std: 180.4132537841797
reward_max: 986.0
reward_min: -38.0
total_envstep_count: 105036
total_train_sample_count: 102910
total_episode_count: 5867
[2024-05-29 03:29:15][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 22.020408163265305
avg_sample_per_episode: 22.020408163265305
avg_envstep_per_sec: 210.95690468613705
avg_train_sample_per_sec: 210.95690468613705
avg_episode_per_sec: 9.58006332680326
reward_mean: 235.3333282470703
reward_std: 181.3721466064453
reward_max: 950.0
reward_min: -50.0
total_envstep_count: 108334
total_train_sample_count: 106147
total_episode_count: 6014
[2024-05-29 03:36:31][sample_serial_collector.py:406][INFO] collect end:
episode_count: 137
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 23.364963503649633
avg_sample_per_episode: 23.364963503649633
avg_envstep_per_sec: 209.3403107961304
avg_train_sample_per_sec: 209.3403107961304
avg_episode_per_sec: 8.959582186526044
reward_mean: 258.08758544921875
reward_std: 182.9429931640625
reward_max: 938.0
reward_min: -38.0
total_envstep_count: 111574
total_train_sample_count: 109348
total_episode_count: 6151
[2024-05-29 03:43:47][sample_serial_collector.py:406][INFO] collect end:
episode_count: 139
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 23.201438848920862
avg_sample_per_episode: 23.201438848920862
avg_envstep_per_sec: 212.36883633265194
avg_train_sample_per_sec: 212.36883633265194
avg_episode_per_sec: 9.153261472942207
reward_mean: 254.94964599609375
reward_std: 181.7259063720703
reward_max: 986.0
reward_min: -38.0
total_envstep_count: 114895
total_train_sample_count: 112573
total_episode_count: 6290
[2024-05-29 03:51:05][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 22.123287671232877
avg_sample_per_episode: 22.123287671232877
avg_envstep_per_sec: 211.73449294262258
avg_train_sample_per_sec: 211.73449294262258
avg_episode_per_sec: 9.570661290904923
reward_mean: 241.0821990966797
reward_std: 172.30239868164062
reward_max: 1016.0
reward_min: -50.0
total_envstep_count: 118257
total_train_sample_count: 115803
total_episode_count: 6436
[2024-05-29 03:58:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 21.775510204081634
avg_sample_per_episode: 21.775510204081634
avg_envstep_per_sec: 209.62393887292131
avg_train_sample_per_sec: 209.62393887292131
avg_episode_per_sec: 9.626591382167895
reward_mean: 242.7346954345703
reward_std: 156.50660705566406
reward_max: 956.0
reward_min: -38.0
total_envstep_count: 121596
total_train_sample_count: 119004
total_episode_count: 6583
[2024-05-29 04:05:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3267
train_sample_count: 3267
avg_envstep_per_episode: 22.224489795918366
avg_sample_per_episode: 22.224489795918366
avg_envstep_per_sec: 210.02660606952418
avg_train_sample_per_sec: 210.02660606952418
avg_episode_per_sec: 9.450232963642502
reward_mean: 249.42857360839844
reward_std: 156.6485595703125
reward_max: 938.0
reward_min: -38.0
total_envstep_count: 124907
total_train_sample_count: 122271
total_episode_count: 6730
[2024-05-29 04:13:03][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 22.34027777777778
avg_sample_per_episode: 22.34027777777778
avg_envstep_per_sec: 208.64903697363482
avg_train_sample_per_sec: 208.64903697363482
avg_episode_per_sec: 9.339590091452724
reward_mean: 235.5833282470703
reward_std: 163.21405029296875
reward_max: 908.0
reward_min: -50.0
total_envstep_count: 128199
total_train_sample_count: 125488
total_episode_count: 6874
[2024-05-29 04:20:19][sample_serial_collector.py:406][INFO] collect end:
episode_count: 145
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 22.06896551724138
avg_sample_per_episode: 22.06896551724138
avg_envstep_per_sec: 208.77949254797477
avg_train_sample_per_sec: 208.77949254797477
avg_episode_per_sec: 9.460320756080106
reward_mean: 238.13792419433594
reward_std: 186.51705932617188
reward_max: 968.0
reward_min: -26.0
total_envstep_count: 131475
total_train_sample_count: 128688
total_episode_count: 7019
[2024-05-29 04:27:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 138
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 23.41304347826087
avg_sample_per_episode: 23.41304347826087
avg_envstep_per_sec: 212.47415641770831
avg_train_sample_per_sec: 212.47415641770831
avg_episode_per_sec: 9.075033607441581
reward_mean: 260.18841552734375
reward_std: 164.12135314941406
reward_max: 920.0
reward_min: -38.0
total_envstep_count: 134791
total_train_sample_count: 131919
total_episode_count: 7157
[2024-05-29 04:34:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 21.91156462585034
avg_sample_per_episode: 21.91156462585034
avg_envstep_per_sec: 209.28804572788127
avg_train_sample_per_sec: 209.28804572788127
avg_episode_per_sec: 9.551487960881262
reward_mean: 237.7142791748047
reward_std: 201.47132873535156
reward_max: 968.0
reward_min: -50.0
total_envstep_count: 138083
total_train_sample_count: 135140
total_episode_count: 7304
[2024-05-29 04:42:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 21.897959183673468
avg_sample_per_episode: 21.897959183673468
avg_envstep_per_sec: 207.93262689319283
avg_train_sample_per_sec: 207.93262689319283
avg_episode_per_sec: 9.495525366045154
reward_mean: 230.23129272460938
reward_std: 148.2598419189453
reward_max: 956.0
reward_min: -50.0
total_envstep_count: 141402
total_train_sample_count: 138359
total_episode_count: 7451
[2024-05-29 04:49:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 155
envstep_count: 3249
train_sample_count: 3249
avg_envstep_per_episode: 20.961290322580645
avg_sample_per_episode: 20.961290322580645
avg_envstep_per_sec: 206.9074458652142
avg_train_sample_per_sec: 206.9074458652142
avg_episode_per_sec: 9.870930781504526
reward_mean: 215.45806884765625
reward_std: 162.6062469482422
reward_max: 884.0
reward_min: -50.0
total_envstep_count: 144689
total_train_sample_count: 141608
total_episode_count: 7606
[2024-05-29 04:56:49][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 22.454545454545453
avg_sample_per_episode: 22.454545454545453
avg_envstep_per_sec: 211.95471808230022
avg_train_sample_per_sec: 211.95471808230022
avg_episode_per_sec: 9.439278942936447
reward_mean: 237.51048278808594
reward_std: 162.0714111328125
reward_max: 974.0
reward_min: -38.0
total_envstep_count: 148011
total_train_sample_count: 144819
total_episode_count: 7749
[2024-05-29 05:04:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3218
train_sample_count: 3218
avg_envstep_per_episode: 22.34722222222222
avg_sample_per_episode: 22.34722222222222
avg_envstep_per_sec: 208.80964153571674
avg_train_sample_per_sec: 208.80964153571674
avg_episode_per_sec: 9.343874574624989
reward_mean: 242.81944274902344
reward_std: 149.3892059326172
reward_max: 998.0
reward_min: -38.0
total_envstep_count: 151281
total_train_sample_count: 148037
total_episode_count: 7893
[2024-05-29 05:11:27][sample_serial_collector.py:406][INFO] collect end:
episode_count: 148
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 21.68243243243243
avg_sample_per_episode: 21.68243243243243
avg_envstep_per_sec: 206.65925592298927
avg_train_sample_per_sec: 206.65925592298927
avg_episode_per_sec: 9.53118413106962
reward_mean: 223.0270233154297
reward_std: 133.76168823242188
reward_max: 890.0
reward_min: -50.0
total_envstep_count: 154613
total_train_sample_count: 151246
total_episode_count: 8041
[2024-05-29 05:18:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3200
train_sample_count: 3200
avg_envstep_per_episode: 22.377622377622377
avg_sample_per_episode: 22.377622377622377
avg_envstep_per_sec: 205.297485382124
avg_train_sample_per_sec: 205.297485382124
avg_episode_per_sec: 9.174231378013667
reward_mean: 247.3986053466797
reward_std: 182.09902954101562
reward_max: 974.0
reward_min: -50.0
total_envstep_count: 157908
total_train_sample_count: 154446
total_episode_count: 8184
[2024-05-29 05:26:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 21.543624161073826
avg_sample_per_episode: 21.543624161073826
avg_envstep_per_sec: 209.2081204127224
avg_train_sample_per_sec: 209.2081204127224
avg_episode_per_sec: 9.710906523830417
reward_mean: 230.91275024414062
reward_std: 163.28680419921875
reward_max: 944.0
reward_min: -38.0
total_envstep_count: 161227
total_train_sample_count: 157656
total_episode_count: 8333
[2024-05-29 05:33:21][sample_serial_collector.py:406][INFO] collect end:
episode_count: 145
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 22.089655172413792
avg_sample_per_episode: 22.089655172413792
avg_envstep_per_sec: 210.99233388679903
avg_train_sample_per_sec: 210.99233388679903
avg_episode_per_sec: 9.551635470991526
reward_mean: 240.17930603027344
reward_std: 182.4989471435547
reward_max: 962.0
reward_min: -50.0
total_envstep_count: 164554
total_train_sample_count: 160859
total_episode_count: 8478
[2024-05-29 05:40:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 154
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 20.805194805194805
avg_sample_per_episode: 20.805194805194805
avg_envstep_per_sec: 210.7309442568282
avg_train_sample_per_sec: 210.7309442568282
avg_episode_per_sec: 10.128765735190868
reward_mean: 219.72727966308594
reward_std: 164.04054260253906
reward_max: 962.0
reward_min: -50.0
total_envstep_count: 167879
total_train_sample_count: 164063
total_episode_count: 8632
[2024-05-29 05:48:01][sample_serial_collector.py:406][INFO] collect end:
episode_count: 142
envstep_count: 3236
train_sample_count: 3236
avg_envstep_per_episode: 22.788732394366196
avg_sample_per_episode: 22.788732394366196
avg_envstep_per_sec: 209.28592265818796
avg_train_sample_per_sec: 209.28592265818796
avg_episode_per_sec: 9.18374567906758
reward_mean: 255.6056365966797
reward_std: 187.287109375
reward_max: 944.0
reward_min: -26.0
total_envstep_count: 171157
total_train_sample_count: 167299
total_episode_count: 8774
[2024-05-29 05:55:24][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3225
train_sample_count: 3225
avg_envstep_per_episode: 21.644295302013422
avg_sample_per_episode: 21.644295302013422
avg_envstep_per_sec: 209.72010397832284
avg_train_sample_per_sec: 209.72010397832284
avg_episode_per_sec: 9.689393951246544
reward_mean: 222.71141052246094
reward_std: 151.29278564453125
reward_max: 986.0
reward_min: -38.0
total_envstep_count: 174473
total_train_sample_count: 170524
total_episode_count: 8923
[2024-05-29 06:02:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 153
envstep_count: 3233
train_sample_count: 3233
avg_envstep_per_episode: 21.130718954248366
avg_sample_per_episode: 21.130718954248366
avg_envstep_per_sec: 209.25377484182374
avg_train_sample_per_sec: 209.25377484182374
avg_episode_per_sec: 9.902823244911547
reward_mean: 221.4509735107422
reward_std: 168.9093475341797
reward_max: 980.0
reward_min: -50.0
total_envstep_count: 177806
total_train_sample_count: 173757
total_episode_count: 9076
[2024-05-29 06:09:59][sample_serial_collector.py:406][INFO] collect end:
episode_count: 160
envstep_count: 3240
train_sample_count: 3240
avg_envstep_per_episode: 20.25
avg_sample_per_episode: 20.25
avg_envstep_per_sec: 208.4235090870564
avg_train_sample_per_sec: 208.4235090870564
avg_episode_per_sec: 10.292518967262044
reward_mean: 203.9499969482422
reward_std: 129.6741943359375
reward_max: 640.0
reward_min: -50.0
total_envstep_count: 181085
total_train_sample_count: 176997
total_episode_count: 9236
[2024-05-29 06:17:12][sample_serial_collector.py:406][INFO] collect end:
episode_count: 136
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 23.625
avg_sample_per_episode: 23.625
avg_envstep_per_sec: 211.52442291694635
avg_train_sample_per_sec: 211.52442291694635
avg_episode_per_sec: 8.953414726643231
reward_mean: 263.2205810546875
reward_std: 186.5900115966797
reward_max: 968.0
reward_min: -50.0
total_envstep_count: 184361
total_train_sample_count: 180210
total_episode_count: 9372
[2024-05-29 06:24:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 139
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 23.12230215827338
avg_sample_per_episode: 23.12230215827338
avg_envstep_per_sec: 210.55114738904308
avg_train_sample_per_sec: 210.55114738904308
avg_episode_per_sec: 9.105976816140942
reward_mean: 254.92086791992188
reward_std: 175.08383178710938
reward_max: 962.0
reward_min: -50.0
total_envstep_count: 187652
total_train_sample_count: 183424
total_episode_count: 9511
[2024-05-29 06:31:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 145
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 22.131034482758622
avg_sample_per_episode: 22.131034482758622
avg_envstep_per_sec: 208.5641413237096
avg_train_sample_per_sec: 208.5641413237096
avg_episode_per_sec: 9.424057492034246
reward_mean: 233.07586669921875
reward_std: 147.0802764892578
reward_max: 700.0
reward_min: 4.0
total_envstep_count: 190930
total_train_sample_count: 186633
total_episode_count: 9656
[2024-05-29 06:39:05][sample_serial_collector.py:406][INFO] collect end:
episode_count: 158
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 20.31645569620253
avg_sample_per_episode: 20.31645569620253
avg_envstep_per_sec: 210.2371876750924
avg_train_sample_per_sec: 210.2371876750924
avg_episode_per_sec: 10.348123256281808
reward_mean: 204.1012725830078
reward_std: 148.1676788330078
reward_max: 956.0
reward_min: -38.0
total_envstep_count: 194220
total_train_sample_count: 189843
total_episode_count: 9814
[2024-05-29 06:46:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 21.986301369863014
avg_sample_per_episode: 21.986301369863014
avg_envstep_per_sec: 208.04958569888473
avg_train_sample_per_sec: 208.04958569888473
avg_episode_per_sec: 9.462691436771705
reward_mean: 236.19178771972656
reward_std: 165.00515747070312
reward_max: 962.0
reward_min: -50.0
total_envstep_count: 197518
total_train_sample_count: 193053
total_episode_count: 9960
[2024-05-29 06:53:45][sample_serial_collector.py:406][INFO] collect end:
episode_count: 142
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 22.598591549295776
avg_sample_per_episode: 22.598591549295776
avg_envstep_per_sec: 207.79013758771225
avg_train_sample_per_sec: 207.79013758771225
avg_episode_per_sec: 9.194826904785023
reward_mean: 256.0281677246094
reward_std: 208.6741485595703
reward_max: 998.0
reward_min: -50.0
total_envstep_count: 200811
total_train_sample_count: 196262
total_episode_count: 10102
[2024-05-29 07:01:00][sample_serial_collector.py:406][INFO] collect end:
episode_count: 151
envstep_count: 3237
train_sample_count: 3237
avg_envstep_per_episode: 21.43708609271523
avg_sample_per_episode: 21.43708609271523
avg_envstep_per_sec: 209.8854694017965
avg_train_sample_per_sec: 209.8854694017965
avg_episode_per_sec: 9.790764868604038
reward_mean: 227.33775329589844
reward_std: 177.8198699951172
reward_max: 986.0
reward_min: -50.0
total_envstep_count: 204141
total_train_sample_count: 199499
total_episode_count: 10253
[2024-05-29 07:08:22][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 21.346666666666668
avg_sample_per_episode: 21.346666666666668
avg_envstep_per_sec: 207.0315719528943
avg_train_sample_per_sec: 207.0315719528943
avg_episode_per_sec: 9.698543345700857
reward_mean: 225.77333068847656
reward_std: 140.50624084472656
reward_max: 956.0
reward_min: -8.0
total_envstep_count: 207412
total_train_sample_count: 202701
total_episode_count: 10403
[2024-05-29 07:15:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3213
train_sample_count: 3213
avg_envstep_per_episode: 22.3125
avg_sample_per_episode: 22.3125
avg_envstep_per_sec: 211.09886218586445
avg_train_sample_per_sec: 211.09886218586445
avg_episode_per_sec: 9.461013431299246
reward_mean: 240.1666717529297
reward_std: 186.9651641845703
reward_max: 962.0
reward_min: -38.0
total_envstep_count: 210698
total_train_sample_count: 205914
total_episode_count: 10547
[2024-05-29 07:22:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 22.27777777777778
avg_sample_per_episode: 22.27777777777778
avg_envstep_per_sec: 208.77321886926097
avg_train_sample_per_sec: 208.77321886926097
avg_episode_per_sec: 9.371366433034158
reward_mean: 241.40277099609375
reward_std: 184.6441192626953
reward_max: 956.0
reward_min: -26.0
total_envstep_count: 213933
total_train_sample_count: 209122
total_episode_count: 10691
[2024-05-29 07:30:17][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 21.931506849315067
avg_sample_per_episode: 21.931506849315067
avg_envstep_per_sec: 208.11243696285445
avg_train_sample_per_sec: 208.11243696285445
avg_episode_per_sec: 9.489199186938396
reward_mean: 226.06849670410156
reward_std: 149.74891662597656
reward_max: 956.0
reward_min: -38.0
total_envstep_count: 217232
total_train_sample_count: 212324
total_episode_count: 10837
[2024-05-29 07:37:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 21.86394557823129
avg_sample_per_episode: 21.86394557823129
avg_envstep_per_sec: 208.27419389497166
avg_train_sample_per_sec: 208.27419389497166
avg_episode_per_sec: 9.525919882564043
reward_mean: 232.35374450683594
reward_std: 145.5146484375
reward_max: 950.0
reward_min: -26.0
total_envstep_count: 220558
total_train_sample_count: 215538
total_episode_count: 10984
[2024-05-29 07:44:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 145
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 22.20689655172414
avg_sample_per_episode: 22.20689655172414
avg_envstep_per_sec: 208.89968133945294
avg_train_sample_per_sec: 208.89968133945294
avg_episode_per_sec: 9.406973228018844
reward_mean: 242.7724151611328
reward_std: 180.8063507080078
reward_max: 980.0
reward_min: -38.0
total_envstep_count: 223918
total_train_sample_count: 218758
total_episode_count: 11129
[2024-05-29 07:52:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3221
train_sample_count: 3221
avg_envstep_per_episode: 21.61744966442953
avg_sample_per_episode: 21.61744966442953
avg_envstep_per_sec: 210.35415207806503
avg_train_sample_per_sec: 210.35415207806503
avg_episode_per_sec: 9.730757112583573
reward_mean: 236.9798583984375
reward_std: 175.30255126953125
reward_max: 998.0
reward_min: -26.0
total_envstep_count: 227258
total_train_sample_count: 221979
total_episode_count: 11278
[2024-05-29 07:59:29][sample_serial_collector.py:406][INFO] collect end:
episode_count: 152
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 21.092105263157894
avg_sample_per_episode: 21.092105263157894
avg_envstep_per_sec: 203.3785892571578
avg_train_sample_per_sec: 203.3785892571578
avg_episode_per_sec: 9.642403483184026
reward_mean: 219.2763214111328
reward_std: 178.94833374023438
reward_max: 974.0
reward_min: -786.0
total_envstep_count: 230554
total_train_sample_count: 225185
total_episode_count: 11430
[2024-05-29 08:06:50][sample_serial_collector.py:406][INFO] collect end:
episode_count: 145
envstep_count: 3217
train_sample_count: 3217
avg_envstep_per_episode: 22.186206896551724
avg_sample_per_episode: 22.186206896551724
avg_envstep_per_sec: 212.69551263534808
avg_train_sample_per_sec: 212.69551263534808
avg_episode_per_sec: 9.58683535347388
reward_mean: 240.48275756835938
reward_std: 144.9615936279297
reward_max: 664.0
reward_min: -26.0
total_envstep_count: 233882
total_train_sample_count: 228402
total_episode_count: 11575
[2024-05-29 08:14:07][sample_serial_collector.py:406][INFO] collect end:
episode_count: 148
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 21.66216216216216
avg_sample_per_episode: 21.66216216216216
avg_envstep_per_sec: 207.4029192798116
avg_train_sample_per_sec: 207.4029192798116
avg_episode_per_sec: 9.574432954900848
reward_mean: 233.51351928710938
reward_std: 168.21859741210938
reward_max: 992.0
reward_min: -38.0
total_envstep_count: 237201
total_train_sample_count: 231608
total_episode_count: 11723
[2024-05-29 08:21:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 22.426573426573427
avg_sample_per_episode: 22.426573426573427
avg_envstep_per_sec: 207.72442466541577
avg_train_sample_per_sec: 207.72442466541577
avg_episode_per_sec: 9.26242367544573
reward_mean: 253.10488891601562
reward_std: 201.08595275878906
reward_max: 1004.0
reward_min: -50.0
total_envstep_count: 240482
total_train_sample_count: 234815
total_episode_count: 11866
[2024-05-29 08:28:49][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3268
train_sample_count: 3268
avg_envstep_per_episode: 21.93288590604027
avg_sample_per_episode: 21.93288590604027
avg_envstep_per_sec: 206.73430027295157
avg_train_sample_per_sec: 206.73430027295157
avg_episode_per_sec: 9.42576828049871
reward_mean: 234.9932861328125
reward_std: 188.73362731933594
reward_max: 968.0
reward_min: -50.0
total_envstep_count: 243809
total_train_sample_count: 238083
total_episode_count: 12015
[2024-05-29 08:36:11][sample_serial_collector.py:406][INFO] collect end:
episode_count: 142
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 22.633802816901408
avg_sample_per_episode: 22.633802816901408
avg_envstep_per_sec: 206.48741510023467
avg_train_sample_per_sec: 206.48741510023467
avg_episode_per_sec: 9.122966068523125
reward_mean: 244.23944091796875
reward_std: 175.16986083984375
reward_max: 980.0
reward_min: -50.0
total_envstep_count: 247120
total_train_sample_count: 241297
total_episode_count: 12157
[2024-05-29 08:43:28][sample_serial_collector.py:406][INFO] collect end:
episode_count: 148
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 21.722972972972972
avg_sample_per_episode: 21.722972972972972
avg_envstep_per_sec: 211.63320858899962
avg_train_sample_per_sec: 211.63320858899962
avg_episode_per_sec: 9.742368544688008
reward_mean: 233.1216278076172
reward_std: 176.2898712158203
reward_max: 956.0
reward_min: -50.0
total_envstep_count: 250406
total_train_sample_count: 244512
total_episode_count: 12305
[2024-05-29 08:50:43][sample_serial_collector.py:406][INFO] collect end:
episode_count: 152
envstep_count: 3208
train_sample_count: 3208
avg_envstep_per_episode: 21.105263157894736
avg_sample_per_episode: 21.105263157894736
avg_envstep_per_sec: 212.080353217751
avg_train_sample_per_sec: 212.080353217751
avg_episode_per_sec: 10.048695040242567
reward_mean: 218.86842346191406
reward_std: 152.7403564453125
reward_max: 968.0
reward_min: -50.0
total_envstep_count: 253685
total_train_sample_count: 247720
total_episode_count: 12457
[2024-05-29 08:58:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 22.426573426573427
avg_sample_per_episode: 22.426573426573427
avg_envstep_per_sec: 207.4870837671768
avg_train_sample_per_sec: 207.4870837671768
avg_episode_per_sec: 9.251840654414183
reward_mean: 242.9510498046875
reward_std: 173.16000366210938
reward_max: 1010.0
reward_min: -38.0
total_envstep_count: 257011
total_train_sample_count: 250927
total_episode_count: 12600
[2024-05-29 09:05:23][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3219
train_sample_count: 3219
avg_envstep_per_episode: 22.354166666666668
avg_sample_per_episode: 22.354166666666668
avg_envstep_per_sec: 206.63865546501899
avg_train_sample_per_sec: 206.63865546501899
avg_episode_per_sec: 9.243854112135052
reward_mean: 247.90277099609375
reward_std: 173.80821228027344
reward_max: 926.0
reward_min: -26.0
total_envstep_count: 260321
total_train_sample_count: 254146
total_episode_count: 12744
[2024-05-29 09:12:40][sample_serial_collector.py:406][INFO] collect end:
episode_count: 152
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 21.07894736842105
avg_sample_per_episode: 21.07894736842105
avg_envstep_per_sec: 207.7868592777127
avg_train_sample_per_sec: 207.7868592777127
avg_episode_per_sec: 9.857553873349666
reward_mean: 220.57894897460938
reward_std: 185.62123107910156
reward_max: 1004.0
reward_min: -50.0
total_envstep_count: 263585
total_train_sample_count: 257350
total_episode_count: 12896
[2024-05-29 09:20:01][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3210
train_sample_count: 3210
avg_envstep_per_episode: 21.4
avg_sample_per_episode: 21.4
avg_envstep_per_sec: 210.78733555397784
avg_train_sample_per_sec: 210.78733555397784
avg_episode_per_sec: 9.849875493176535
reward_mean: 224.75999450683594
reward_std: 167.26358032226562
reward_max: 974.0
reward_min: -50.0
total_envstep_count: 266843
total_train_sample_count: 260560
total_episode_count: 13046
[2024-05-29 09:27:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 154
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 20.90909090909091
avg_sample_per_episode: 20.90909090909091
avg_envstep_per_sec: 206.59623180055397
avg_train_sample_per_sec: 206.59623180055397
avg_episode_per_sec: 9.880689346983015
reward_mean: 212.0129852294922
reward_std: 129.64857482910156
reward_max: 634.0
reward_min: -50.0
total_envstep_count: 270140
total_train_sample_count: 263780
total_episode_count: 13200
[2024-05-29 09:34:39][sample_serial_collector.py:406][INFO] collect end:
episode_count: 154
envstep_count: 3214
train_sample_count: 3214
avg_envstep_per_episode: 20.87012987012987
avg_sample_per_episode: 20.87012987012987
avg_envstep_per_sec: 206.27840232826375
avg_train_sample_per_sec: 206.27840232826375
avg_episode_per_sec: 9.88390602319621
reward_mean: 218.0779266357422
reward_std: 146.46322631835938
reward_max: 944.0
reward_min: -50.0
total_envstep_count: 273412
total_train_sample_count: 266994
total_episode_count: 13354
[2024-05-29 09:41:53][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3251
train_sample_count: 3251
avg_envstep_per_episode: 22.267123287671232
avg_sample_per_episode: 22.267123287671232
avg_envstep_per_sec: 207.1664967997942
avg_train_sample_per_sec: 207.1664967997942
avg_episode_per_sec: 9.303693796607185
reward_mean: 243.02740478515625
reward_std: 216.2844696044922
reward_max: 974.0
reward_min: -38.0
total_envstep_count: 276771
total_train_sample_count: 270245
total_episode_count: 13500
[2024-05-29 09:49:12][sample_serial_collector.py:406][INFO] collect end:
episode_count: 153
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 20.96078431372549
avg_sample_per_episode: 20.96078431372549
avg_envstep_per_sec: 208.5440280856155
avg_train_sample_per_sec: 208.5440280856155
avg_episode_per_sec: 9.949247364234228
reward_mean: 218.5098114013672
reward_std: 175.1180419921875
reward_max: 974.0
reward_min: -38.0
total_envstep_count: 280037
total_train_sample_count: 273452
total_episode_count: 13653
[2024-05-29 09:56:30][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3206
train_sample_count: 3206
avg_envstep_per_episode: 22.26388888888889
avg_sample_per_episode: 22.26388888888889
avg_envstep_per_sec: 210.53429821879615
avg_train_sample_per_sec: 210.53429821879615
avg_episode_per_sec: 9.45631283328342
reward_mean: 235.55555725097656
reward_std: 168.29611206054688
reward_max: 956.0
reward_min: -38.0
total_envstep_count: 283330
total_train_sample_count: 276658
total_episode_count: 13797
[2024-05-29 10:03:52][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 21.35333333333333
avg_sample_per_episode: 21.35333333333333
avg_envstep_per_sec: 208.07089011747473
avg_train_sample_per_sec: 208.07089011747473
avg_episode_per_sec: 9.744187798195819
reward_mean: 221.6666717529297
reward_std: 149.0631103515625
reward_max: 992.0
reward_min: -50.0
total_envstep_count: 286632
total_train_sample_count: 279861
total_episode_count: 13947
[2024-05-29 10:11:09][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 21.97945205479452
avg_sample_per_episode: 21.97945205479452
avg_envstep_per_sec: 203.20959149160663
avg_train_sample_per_sec: 203.20959149160663
avg_episode_per_sec: 9.245434826355428
reward_mean: 240.30137634277344
reward_std: 171.5135498046875
reward_max: 986.0
reward_min: -50.0
total_envstep_count: 289900
total_train_sample_count: 283070
total_episode_count: 14093
[2024-05-29 10:18:31][sample_serial_collector.py:406][INFO] collect end:
episode_count: 143
envstep_count: 3209
train_sample_count: 3209
avg_envstep_per_episode: 22.44055944055944
avg_sample_per_episode: 22.44055944055944
avg_envstep_per_sec: 208.38129572878228
avg_train_sample_per_sec: 208.38129572878228
avg_episode_per_sec: 9.285922495860351
reward_mean: 242.18182373046875
reward_std: 179.6275634765625
reward_max: 986.0
reward_min: -26.0
total_envstep_count: 293171
total_train_sample_count: 286279
total_episode_count: 14236
[2024-05-29 10:25:46][sample_serial_collector.py:406][INFO] collect end:
episode_count: 140
envstep_count: 3223
train_sample_count: 3223
avg_envstep_per_episode: 23.021428571428572
avg_sample_per_episode: 23.021428571428572
avg_envstep_per_sec: 207.99991766405037
avg_train_sample_per_sec: 207.99991766405037
avg_episode_per_sec: 9.035056926145533
reward_mean: 257.471435546875
reward_std: 193.31744384765625
reward_max: 980.0
reward_min: -38.0
total_envstep_count: 296498
total_train_sample_count: 289502
total_episode_count: 14376
[2024-05-29 10:33:01][sample_serial_collector.py:406][INFO] collect end:
episode_count: 157
envstep_count: 3203
train_sample_count: 3203
avg_envstep_per_episode: 20.401273885350317
avg_sample_per_episode: 20.401273885350317
avg_envstep_per_sec: 211.78674071060988
avg_train_sample_per_sec: 211.78674071060988
avg_episode_per_sec: 10.381054727307445
reward_mean: 208.80255126953125
reward_std: 167.95098876953125
reward_max: 944.0
reward_min: -50.0
total_envstep_count: 299781
total_train_sample_count: 292705
total_episode_count: 14533
[2024-05-29 10:40:16][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3216
train_sample_count: 3216
avg_envstep_per_episode: 21.583892617449663
avg_sample_per_episode: 21.583892617449663
avg_envstep_per_sec: 208.2611991410111
avg_train_sample_per_sec: 208.2611991410111
avg_episode_per_sec: 9.64891749751575
reward_mean: 228.89932250976562
reward_std: 165.86021423339844
reward_max: 938.0
reward_min: -50.0
total_envstep_count: 303087
total_train_sample_count: 295921
total_episode_count: 14682
[2024-05-29 10:47:36][sample_serial_collector.py:406][INFO] collect end:
episode_count: 147
envstep_count: 3207
train_sample_count: 3207
avg_envstep_per_episode: 21.816326530612244
avg_sample_per_episode: 21.816326530612244
avg_envstep_per_sec: 210.4728085697245
avg_train_sample_per_sec: 210.4728085697245
avg_episode_per_sec: 9.647490757639382
reward_mean: 233.91836547851562
reward_std: 172.4796142578125
reward_max: 980.0
reward_min: -50.0
total_envstep_count: 306375
total_train_sample_count: 299128
total_episode_count: 14829
[2024-05-29 10:54:46][sample_serial_collector.py:406][INFO] collect end:
episode_count: 151
envstep_count: 3205
train_sample_count: 3205
avg_envstep_per_episode: 21.225165562913908
avg_sample_per_episode: 21.225165562913908
avg_envstep_per_sec: 205.83394386796502
avg_train_sample_per_sec: 205.83394386796502
avg_episode_per_sec: 9.697636668974328
reward_mean: 224.52980041503906
reward_std: 173.4801025390625
reward_max: 1004.0
reward_min: -50.0
total_envstep_count: 309689
total_train_sample_count: 302333
total_episode_count: 14980
[2024-05-29 11:02:04][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3201
train_sample_count: 3201
avg_envstep_per_episode: 21.483221476510067
avg_sample_per_episode: 21.483221476510067
avg_envstep_per_sec: 207.55628046218894
avg_train_sample_per_sec: 207.55628046218894
avg_episode_per_sec: 9.661320146474898
reward_mean: 229.57046508789062
reward_std: 146.26547241210938
reward_max: 968.0
reward_min: 4.0
total_envstep_count: 312982
total_train_sample_count: 305534
total_episode_count: 15129
[2024-05-29 11:09:13][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3256
train_sample_count: 3256
avg_envstep_per_episode: 22.301369863013697
avg_sample_per_episode: 22.301369863013697
avg_envstep_per_sec: 211.3848541126241
avg_train_sample_per_sec: 211.3848541126241
avg_episode_per_sec: 9.478559183182776
reward_mean: 244.38356018066406
reward_std: 188.08790588378906
reward_max: 992.0
reward_min: -26.0
total_envstep_count: 316298
total_train_sample_count: 308790
total_episode_count: 15275
[2024-05-29 11:16:26][sample_serial_collector.py:406][INFO] collect end:
episode_count: 144
envstep_count: 3202
train_sample_count: 3202
avg_envstep_per_episode: 22.23611111111111
avg_sample_per_episode: 22.23611111111111
avg_envstep_per_sec: 204.74712020890834
avg_train_sample_per_sec: 204.74712020890834
avg_episode_per_sec: 9.207865493467459
reward_mean: 235.30555725097656
reward_std: 156.0217742919922
reward_max: 1004.0
reward_min: -50.0
total_envstep_count: 319581
total_train_sample_count: 311992
total_episode_count: 15419
[2024-05-29 11:23:32][sample_serial_collector.py:406][INFO] collect end:
episode_count: 158
envstep_count: 3235
train_sample_count: 3235
avg_envstep_per_episode: 20.474683544303797
avg_sample_per_episode: 20.474683544303797
avg_envstep_per_sec: 207.33390911033362
avg_train_sample_per_sec: 207.33390911033362
avg_episode_per_sec: 10.126354757166217
reward_mean: 204.83544921875
reward_std: 138.78245544433594
reward_max: 932.0
reward_min: -38.0
total_envstep_count: 322895
total_train_sample_count: 315227
total_episode_count: 15577
[2024-05-29 11:30:48][sample_serial_collector.py:406][INFO] collect end:
episode_count: 146
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 22.13013698630137
avg_sample_per_episode: 22.13013698630137
avg_envstep_per_sec: 209.5638720581548
avg_train_sample_per_sec: 209.5638720581548
avg_episode_per_sec: 9.469614769573074
reward_mean: 239.05479431152344
reward_std: 175.33470153808594
reward_max: 1004.0
reward_min: -38.0
total_envstep_count: 326187
total_train_sample_count: 318458
total_episode_count: 15723
[2024-05-29 11:37:56][sample_serial_collector.py:406][INFO] collect end:
episode_count: 153
envstep_count: 3211
train_sample_count: 3211
avg_envstep_per_episode: 20.986928104575163
avg_sample_per_episode: 20.986928104575163
avg_envstep_per_sec: 210.07458349083333
avg_train_sample_per_sec: 210.07458349083333
avg_episode_per_sec: 10.009782396168639
reward_mean: 210.771240234375
reward_std: 151.0245819091797
reward_max: 968.0
reward_min: -50.0
total_envstep_count: 329458
total_train_sample_count: 321669
total_episode_count: 15876
[2024-05-29 11:45:10][sample_serial_collector.py:406][INFO] collect end:
episode_count: 150
envstep_count: 3230
train_sample_count: 3230
avg_envstep_per_episode: 21.533333333333335
avg_sample_per_episode: 21.533333333333335
avg_envstep_per_sec: 206.2009190924917
avg_train_sample_per_sec: 206.2009190924917
avg_episode_per_sec: 9.57589407550271
reward_mean: 228.26666259765625
reward_std: 181.88107299804688
reward_max: 968.0
reward_min: -50.0
total_envstep_count: 332781
total_train_sample_count: 324899
total_episode_count: 16026
[2024-05-29 11:52:17][sample_serial_collector.py:406][INFO] collect end:
episode_count: 164
envstep_count: 3231
train_sample_count: 3231
avg_envstep_per_episode: 19.701219512195124
avg_sample_per_episode: 19.701219512195124
avg_envstep_per_sec: 205.06906461978733
avg_train_sample_per_sec: 205.06906461978733
avg_episode_per_sec: 10.408952831211737
reward_mean: 198.756103515625
reward_std: 143.86651611328125
reward_max: 938.0
reward_min: -50.0
total_envstep_count: 336051
total_train_sample_count: 328130
total_episode_count: 16190
[2024-05-29 11:59:29][sample_serial_collector.py:406][INFO] collect end:
episode_count: 162
envstep_count: 3204
train_sample_count: 3204
avg_envstep_per_episode: 19.77777777777778
avg_sample_per_episode: 19.77777777777778
avg_envstep_per_sec: 208.92192180711675
avg_train_sample_per_sec: 208.92192180711675
avg_episode_per_sec: 10.563467956539611
reward_mean: 191.59259033203125
reward_std: 150.6339111328125
reward_max: 962.0
reward_min: -26.0
total_envstep_count: 339375
total_train_sample_count: 331334
total_episode_count: 16352
[2024-05-29 12:06:38][sample_serial_collector.py:406][INFO] collect end:
episode_count: 149
envstep_count: 3215
train_sample_count: 3215
avg_envstep_per_episode: 21.57718120805369
avg_sample_per_episode: 21.57718120805369
avg_envstep_per_sec: 207.56306539767783
avg_train_sample_per_sec: 207.56306539767783
avg_episode_per_sec: 9.619563528539347
reward_mean: 237.63758850097656
reward_std: 171.6265869140625
reward_max: 950.0
reward_min: -38.0
total_envstep_count: 342676
total_train_sample_count: 334549
total_episode_count: 16501
[2024-05-29 12:13:49][sample_serial_collector.py:406][INFO] collect end:
episode_count: 155
envstep_count: 3220
train_sample_count: 3220
avg_envstep_per_episode: 20.774193548387096
avg_sample_per_episode: 20.774193548387096
avg_envstep_per_sec: 204.54451587101846
avg_train_sample_per_sec: 204.54451587101846
avg_episode_per_sec: 9.84608694410182
reward_mean: 218.1161346435547
reward_std: 151.6640167236328
reward_max: 1004.0
reward_min: -50.0
total_envstep_count: 345923
total_train_sample_count: 337769
total_episode_count: 16656
